[{"categories":["microservices"],"contents":"Why and What? In Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill, as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.\nThis is the very scenario where things can fall apart very easily!\nWhy Docker? In scenarios like mentioned above, wouldn\u0026rsquo;t it be useful to have a tool that makes sure that a software is bundled in a way that is irrespective of the base dependencies it requires to be built on?\nAs I primarily work in Python, I would like to throw in an analogy. This abstraction tool can be thought of like a virual environment, with each project having its own separate dependencies which do not interfere with a different project\u0026rsquo;s virtual environment, and every project satisfies all the module level dependencies it has once run from inside the virtual environment.\nHaving such a tool to manage whole software, such that it handles all the base dependencies like that of the OS and any other package level dependencies are managed for us would be great, wouldn\u0026rsquo;t it?\nWhat is Docker? In-line with the objectives that we want the above-mentioned tool to perform, let\u0026rsquo;s take a look at Docker.\nDocker helps abstract away the dependencies for components between varying OS and hardware requirements, and lets every part of the project run in an isolated environment.\nFeels like technical mumbo jumbo? Well let\u0026rsquo;s take another go at understanding this. The abstraction that Docker provides can be thought of in the following way:\nImagine breaking the whole software into multiple smaller pieces, with each piece handling one complete part of some logic. This is what we call an isolated part of the project. For the whole application to be able to run, we need each of the isolated part of the project we created in the step above to be able to run. To be able to run each isolated part of the project, we need to satisfy the dependencies that every isolated part needs. Satisfying these dependencies can be thought of as creating environments for each part of the project that we isolated. I hope it is more or less clear what Docker does. If not, fret not! Things should become clearer as we go further with terminology.\nTerminology So far, we have been trying to understand what Docker does in our own analogy and terms. However, things can go out of hand if one does not follow a standard terminology.\nLet\u0026rsquo;s dive in the terminology that will make our life easier to follow.\nObviously, one should at the end refer to the official glossary mentioned by Docker. However, to quickly get us started, I have mentioned some base terminologies below.\nImage Since we need to create an isolated environment, we first need to decide what will the base of such an environment have. This base that each isolated environment needs is defined in a Docker image, which contains union of layered filesystems stacked on top of each other.\nWe can think of image as a small pre-compiled software on which we can run our assigned part of the project, and using an image is like installing Python or Ubuntu on your own machine.\nBecause of the awesome strength of the Docker community, they decided to keep a collection of the images that people need. This collection of images is listed on the Docker Hub, and we can find all sorts of images, like Alpine Linux and Python.\nNote: Although the Docker hub has many images readily available, we can also create our own Docker images.\nContainer With the image\nlike having multiple small-separate machines running different pieces of the software (which we specify), running the whole software as Lego blocks, with each of the small machines helping each other.\nContainers in Docker have their own network, their own volume mounts, their own networks, and are just like VMs. The only difference is that all the containers share the same os as the machine on which they are running, unlike VMs who also have their own OS when created.\nContainer use the kernel to run their process. In such, a linux based OS will only be able to run linux based containers on it, and a windows based container will not be able to run on a windows based machine.\nImages in Docker are packages or templates that are used to create one or more containers. every container needs an image to be able to run.\nDockerFile is the configuration of an image should be initialized. DockerFile creates a Docker image, and image runs a container.\n","permalink":"http://localhost:1313/posts/docker/docker_images/","tags":["Docker","microservices"],"title":"Docker Images and DockerFile"},{"categories":["Docker"],"contents":"Why and What‚ÅâÔ∏è Ô∏èIn Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.\nThis is the very scenario where things can fall apart very easily!\nWhy Dockerü§î In scenarios like mentioned above, wouldn\u0026rsquo;t it be useful to have a tool that makes sure that a software is bundled in a way that is irrespective of the base dependencies it requires to be built on?\nAs I primarily work in Pythonüêç, I would like to throw in an analogy. This abstraction tool can be thought of like a virual environment, with each project having its own separate dependencies which do not interfere with a different project\u0026rsquo;s virtual environment, and every environment satisfying all the module level dependencies that the project needs.\nIn short, the tool that we need should have isolation and dependency matched as per the part of the project that is running on it!\nHaving such a tool to manage whole software, such that it handles all the base dependencies like that of the OS and any other package level dependencies are managed for us would be great, wouldn\u0026rsquo;t it?\nWhat is Dockerüê≥ In-line with the objectives that we want the above-mentioned tool to perform, let\u0026rsquo;s take a look at Docker.\nDocker helps abstract away the dependencies for components between varying OS, software, and hardware requirements, and lets every part of the project run in an isolated environment.\nFeels like technical mumbo jumbo? Well let\u0026rsquo;s take another go at understanding this. The abstraction that Docker provides can be thought of in the following way:\nImagine breaking the whole software into multiple smaller pieces, with each piece handling one part of some logic. This is what we call an isolated part of the project. Each part will naturally have a set of requirements in the forms of packages or configurations for it to be able to run correctly. This is the dependency that the project has. Running our project using Docker will abstract away the above said requirements for other people, and anybody running our project will use the configurations we have set when moving the project to Docker. I hope it is more or less clear what Docker does. If not, fret not! Things should become clearer as we go further with terminology.\nTerminologyüìñ So far, we have been trying to understand what Docker does in our own analogy and terms. However, things can go out of hand if one does not follow a standard terminologyüê±.\nLet\u0026rsquo;s dive in the terminology that will make our life easier to follow.\nObviously, one should at the end refer to the official glossary mentioned by Docker. However, to quickly get us started, I have mentioned some base terminologies below.\nDocker Image‚úíÔ∏è Since we need to create an isolated environment, we first need to decide what will the base of such an environment have. This base that each isolated environment needs is defined in a Docker image, which contains union of layered filesystems stacked on top of each other.\nWe can think of image as a small pre-compiled software on which we can run our assigned part of the project, and using an image is like installing Python or Ubuntu on your own machine.\nBecause of the awesome strength of the Docker community, they decided to keep a collection of the images that people need. This collection of images is listed on the Docker Hub, and we can find all sorts of images, like Alpine Linux and Python.\nNote: Although the Docker hub has many images readily available, we can also create our own Docker images. And as we read above that images are union of layered filesystems, our own image will also be a layer over some base image.\nA more detailed explanation of Docker Images is here.\nDocker Containerüì¶ So we saw that image in Docker is a base system that we want to run our piece of the project. When we run such an image, we get a Docker container.\nIn short, a Docker container is a running instance of a Docker image.\nA container always needs an image, and along with it, we sometimes pass a set of execution parameters such that the container has the parameters that we want, for example it\u0026rsquo;s name.\nA more detailed explanation of Docker containers is here.\nSumming it up!üí° What we saw so far is a very basic understanding of what Docker is, why we might need it, and what are the basic things we need to understand for breaking our project into small running containers. In the next part, let\u0026rsquo;s look at Docker Images in a bit more detail and how we can create our image. üò∫\n","permalink":"http://localhost:1313/posts/docker/docker_intro/","tags":["Docker","Microservices"],"title":"The basics of Docker to get started"},{"categories":["microservices"],"contents":"Why and What? In Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill, as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.\nThis is the very scenario where things can fall apart very easily!\nWhy Docker? In scenarios like mentioned above, wouldn\u0026rsquo;t it be useful to have a tool that makes sure that a software is bundled in a way that is irrespective of the base dependencies it requires to be built on?\nAs I primarily work in Python, I would like to throw in an analogy. This abstraction tool can be thought of like a virual environment, with each project having its own separate dependencies which do not interfere with a different project\u0026rsquo;s virtual environment, and every project satisfies all the module level dependencies it has once run from inside the virtual environment.\nHaving such a tool to manage whole software, such that it handles all the base dependencies like that of the OS and any other package level dependencies are managed for us would be great, wouldn\u0026rsquo;t it?\nWhat is Docker? In-line with the objectives that we want the above-mentioned tool to perform, let\u0026rsquo;s take a look at Docker.\nDocker helps abstract away the dependencies for components between varying OS and hardware requirements, and lets every part of the project run in an isolated environment.\nFeels like technical mumbo jumbo? Well let\u0026rsquo;s take another go at understanding this. The abstraction that Docker provides can be thought of in the following way:\nImagine breaking the whole software into multiple smaller pieces, with each piece handling one complete part of some logic. This is what we call an isolated part of the project. For the whole application to be able to run, we need each of the isolated part of the project we created in the step above to be able to run. To be able to run each isolated part of the project, we need to satisfy the dependencies that every isolated part needs. Satisfying these dependencies can be thought of as creating environments for each part of the project that we isolated. I hope it is more or less clear what Docker does. If not, fret not! Things should become clearer as we go further with terminology.\nTerminology So far, we have been trying to understand what Docker does in our own analogy and terms. However, things can go out of hand if one does not follow a standard terminology.\nLet\u0026rsquo;s dive in the terminology that will make our life easier to follow.\nObviously, one should at the end refer to the official glossary mentioned by Docker. However, to quickly get us started, I have mentioned some base terminologies below.\nImage Since we need to create an isolated environment, we first need to decide what will the base of such an environment have. This base that each isolated environment needs is defined in a Docker image, which contains union of layered filesystems stacked on top of each other.\nWe can think of image as a small pre-compiled software on which we can run our assigned part of the project, and using an image is like installing Python or Ubuntu on your own machine.\nBecause of the awesome strength of the Docker community, they decided to keep a collection of the images that people need. This collection of images is listed on the Docker Hub, and we can find all sorts of images, like Alpine Linux and Python.\nNote: Although the Docker hub has many images readily available, we can also create our own Docker images.\nContainer With the image\nlike having multiple small-separate machines running different pieces of the software (which we specify), running the whole software as Lego blocks, with each of the small machines helping each other.\nContainers in Docker have their own network, their own volume mounts, their own networks, and are just like VMs. The only difference is that all the containers share the same os as the machine on which they are running, unlike VMs who also have their own OS when created.\nContainer use the kernel to run their process. In such, a linux based OS will only be able to run linux based containers on it, and a windows based container will not be able to run on a windows based machine.\nImages in Docker are packages or templates that are used to create one or more containers. every container needs an image to be able to run.\nDockerFile is the configuration of an image should be initialized. DockerFile creates a Docker image, and image runs a container.\n","permalink":"http://localhost:1313/posts/docker/docker_containers/","tags":["Docker","microservices"],"title":"The basics of Images to get started"}]