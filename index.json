[{"content":"Why and What‚ÅâÔ∏è Ô∏èIn Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.\nThis is the very scenario where things can fall apart very easily!\nWhy Dockerü§î In scenarios like mentioned above, wouldn\u0026rsquo;t it be useful to have a tool that makes sure that a software is bundled in a way that is irrespective of the base dependencies it requires to be built on?\nAs I primarily work in Pythonüêç, I would like to throw in an analogy. This abstraction tool can be thought of like a virtual environment, with each project having its own separate dependencies which do not interfere with a different project\u0026rsquo;s virtual environment, and every environment satisfying all the module level dependencies that the project needs.\nIn short, the tool that we need should have isolation and dependency matched as per the part of the project that is running on it!\nHaving such a tool to manage whole software, such that it handles all the base dependencies like that of the OS and any other package level dependencies are managed for us would be great, wouldn\u0026rsquo;t it?\nWhat is Dockerüê≥ In-line with the objectives that we want the above-mentioned tool to perform, let\u0026rsquo;s take a look at Docker.\nDocker helps abstract away the dependencies for components between varying OS, software, and hardware requirements, and lets every part of the project run in an isolated environment.\nFeels like technical mumbo jumbo? Well let\u0026rsquo;s take another go at understanding this. The abstraction that Docker provides can be thought of in the following way:\nImagine breaking the whole software into multiple smaller pieces, with each piece handling one part of some logic. This is what we call an isolated part of the project. Each part will naturally have a set of requirements in the forms of packages or configurations for it to be able to run correctly. This is the dependency that the project has. Running our project using Docker will abstract away the above said requirements for other people, and anybody running our project will use the configurations we have set when moving the project to Docker. I hope it is more or less clear what Docker does. If not, fret not! Things should become clearer as we go further with terminology.\nTerminologyüìñ So far, we have been trying to understand what Docker does in our own analogy and terms. However, things can go out of hand if one does not follow a standard terminologyüê±.\nLet\u0026rsquo;s dive in the terminology that will make our life easier to follow.\nObviously, one should at the end refer to the official glossary mentioned by Docker. However, to quickly get us started, I have mentioned some base terminologies below.\nDocker Image‚úíÔ∏è Since we need to create an isolated environment, we first need to decide what will the base of such an environment have. This base that each isolated environment needs is defined in a Docker image, which contains union of layered filesystems stacked on top of each other.\nWe can think of image as a small pre-compiled software on which we can run our assigned part of the project, and using an image is like installing Python or Ubuntu on your own machine.\nBecause of the awesome strength of the Docker community, they decided to keep a collection of the images that people need. This collection of images is listed on the Docker Hub, and we can find all sorts of images, like Alpine Linux and Python.\nNote: Although the Docker hub has many images readily available, we can also create our own Docker images. And as we read above that images are union of layered filesystems, our own image will also be a layer over some base image.\nA more detailed explanation of Docker Images is here.\nDocker Containerüì¶ So we saw that image in Docker is a base system that we want to run our piece of the project. When we run such an image, we get a Docker container.\nIn short, a Docker container is a running instance of a Docker image.\nA container always needs an image, and along with it, we sometimes pass a set of execution parameters such that the container has the parameters that we want, for example it\u0026rsquo;s name.\nA more detailed explanation of Docker containers is here.\nSumming it up!üí° What we saw so far is a very basic understanding of what Docker is, why we might need it, and what are the basic things we need to understand for breaking our project into small running containers. These small running containers can also be thought of as very small virtual machines, and this will be more clear when we look at the Docker Containers post. In the next part, let\u0026rsquo;s look at Docker Images in a bit more detail and how we can create our image. üò∫\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_intro/","summary":"Why and What‚ÅâÔ∏è Ô∏èIn Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.","title":"The basics of Docker to get started"},{"content":"What is a configuration file‚ÅâÔ∏è A configuration file is a text file that contains various settings and options that control the behavior of a software program or system. The file is usually written in a specific format, such as JSON, YAML,INI, or TOML and is read by the program or system at startup. The settings in the configuration file can be modified to change the behavior of the program or system without having to change the code.\nA configuration file can include options such as the location of other files or resources, user preferences, settings for different environments (e.g. development, production), and various other parameters that control how the program or system behaves. Configuration files are often used to configure servers, network devices, and other types of systems.\nFor example, a web server might have a configuration file that specifies the IP address and port it should listen on, the document root for the web server, and other settings related to security, logging, and performance.\nBy using configuration files, administrators and developers can easily configure and customize the behavior of a program or system without having to modify the code or recompile the program.\nWhat is the JSON configuration file‚ùì A JSON (JavaScript Object Notation) configuration file is a file format that stores simple data structures and objects in a human-readable, easy-to-access manner. JSON files are often used to store configuration settings and data for software applications, and can be easily read and edited by both humans and machines. They are typically saved with a .JSON file extension and use a syntax similar to that of JavaScript objects. JSON files can be easily parsed and processed by many programming languages, making them a popular choice for configuration files.\nExample of a JSON file might look like this:\n{ \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34;, \u0026#34;key3\u0026#34;: { \u0026#34;subkey1\u0026#34;: \u0026#34;subvalue1\u0026#34;, \u0026#34;subkey2\u0026#34;: \u0026#34;subvalue2\u0026#34; }, \u0026#34;key4\u0026#34;: [ \u0026#34;arrayvalue1\u0026#34;, \u0026#34;arrayvalue2\u0026#34;, \u0026#34;arrayvalue3\u0026#34; ] } Things to note about a JSON file JSON files consist of key-value pairs, similar to a JavaScript object.\nThe keys are strings, enclosed in double quotes, and the values can be either \u0026lsquo;strings\u0026rsquo;, \u0026rsquo;numbers\u0026rsquo;, \u0026lsquo;objects\u0026rsquo; (enclosed in curly braces), \u0026lsquo;arrays\u0026rsquo; (enclosed in square brackets), or special values \u0026rsquo;true\u0026rsquo;, \u0026lsquo;false\u0026rsquo;, and \u0026rsquo;null\u0026rsquo;.\nString values must also be enclosed in double quotes (\u0026quot;).\nWhat is the YAML configuration file‚ùì YAML (short for \u0026ldquo;YAML Ain\u0026rsquo;t Markup Language\u0026rdquo;) is a human-readable data serialization format that is often used for configuration files, data exchange, and data structuring. It is designed to be easy to read and write, and is often used as an alternative to XML or JSON.\nA YAML file is a text file that contains data structured in a specific way. It uses indentation and whitespace to indicate the structure of the data, making it easy to read and understand. The basic building blocks of a YAML file are key-value pairs, which are separated by a colon. Lists and arrays are also supported, and can be represented using a simple syntax.\nExample of a simple YAML file might look like this:\nname: John Doe age: 35 address: street: 123 Main St city: Anytown state: CA zip: 12345 YAML files are often used for configuration files because they are easy to read and understand, and are less verbose than other formats such as XML or JSON. They are also used in various tools and frameworks such as Ansible, Kubernetes, and Docker Compose, where they are used to define the configuration of the system.\nIt\u0026rsquo;s important to note that YAML is case-sensitive and indentation is important, so if you don\u0026rsquo;t use proper indentation or typo the key names it will cause errors.\nThings to note about a YAML file In a YAML file, indentation is used to indicate the hierarchical structure of the data. Each level of indentation represents a new level in the data hierarchy.\nFor example, in the above YAML file, the \u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;, and \u0026lsquo;address\u0026rsquo; keys are at the same level, and are considered to be siblings. The \u0026lsquo;street\u0026rsquo;, \u0026lsquo;city\u0026rsquo;, \u0026lsquo;state\u0026rsquo;, and \u0026lsquo;zip\u0026rsquo; keys are indented under the address key, indicating that they are child elements of the address element.\nIt is important to use consistent indentation throughout the YAML file. Typically, two spaces are used for each level of indentation, but it can vary. However, it is important to use the same number of spaces throughout the file, as YAML is sensitive to indentation. An error in indentation can cause the YAML file to be parsed incorrectly, resulting in errors when the file is read by the software that uses it.\nAlso, YAML files use the dash - to indicate the start of a list, for example:\nfruits: - apple - banana - orange In this example, fruits is a key and the indented items are the list of values for the key.\nWhat is the INI configuration file‚ùì An INI (Initialization) file is a configuration file used by some software applications to store settings and options. It is a simple text file that contains key-value pairs organized into sections. The format of an INI file is similar to that of a Windows INI file, although it is not limited to Windows.\nHere is an example of the structure of an INI file:\n[section1] key1=value1 key2=value2 [section2] key3=value3 key4=value4 Things to note about the INI file INI files are composed of sections, which are enclosed in square brackets [].\nEach section contains one or more key-value pairs, separated by an equal sign =. The key is a unique string that identifies the value, and the value is an arbitrary string that represents the data.\nComments can also be added by starting the line with a semi-colon ; or a hash #.\nINI files are often used to store application settings and options, such as user preferences or connection settings.\nUnlike JSON or XML, INI files are not formal, standard format and the syntax may vary depending on the application which uses it. They are often used for simple configuration settings where a more complex format is not required.\nNOTE: It\u0026rsquo;s important to note that the INI file format does not have a formal specification and thus the syntax may vary depending on the application that uses it. However, most implementations follow the above structure and this is a common format for INI files.\nWhat is the TOML configuration file‚ùì TOML (Tom\u0026rsquo;s Obvious, Minimal Language) is a configuration file format that is similar to INI files but with some additional features. It is designed to be easy to read and write, and is intended to be a more robust and consistent alternative to INI files.\nBelow is an example of how a TOML file looks like:\n[section1] key1 = \u0026#34;value1\u0026#34; key2 = \u0026#34;value2\u0026#34; [section2] key3 = \u0026#34;value3\u0026#34; key4 = \u0026#34;value4\u0026#34; Things to note about the TOML file TOML files are divided into sections, which are enclosed in square brackets [], just like the ini files.\nEach section contains one or more key-value pairs, separated by an equal sign =.\nThe keys must be unique within the section, and they are case-sensitive.\nThe values can be strings, integers, floats, booleans, and datetime.\nTOML files support inline comments, with the # symbol.\nTOML is designed to be easy to parse, and it is more consistent than INI files. It is also more expressive and can handle more complex data types. TOML is used as a configuration file format in a number of programming languages and projects, such as Rust and Cargo.\nCongratulationsüôåüéâü•≥üôåüéâü•≥ We saw in this post the common types of configuration files that are used to create a set of settings that a particular user or a software wants to be executed as defined in the configuration file.\nNow you are a pro at creating your own configuration file, and can use as many configuration files as you want in your software!! Until next time üòéüòéüòé\n","permalink":"https://tanmaychimurkar.github.io/posts/configurations/yaml_files/","summary":"What is a configuration file‚ÅâÔ∏è A configuration file is a text file that contains various settings and options that control the behavior of a software program or system. The file is usually written in a specific format, such as JSON, YAML,INI, or TOML and is read by the program or system at startup. The settings in the configuration file can be modified to change the behavior of the program or system without having to change the code.","title":"Configuration files"},{"content":"Docker Imagesüê≥ As we saw in the basics of Docker post, the base flow of every Docker container is an image. A Docker image, whether custom or pre-built, is absolutely necessary for us to be able to run anything using Docker.\nIn essence, a Docker image is a union of layered filesystem stacked on top of each other. This stands true for pre-built images as well as custom images that we might create using some pre-built image as a base.\nTriviaüí°: If every Docker image is a set of layered instructions, then how is the first Docker image created? What did the very first Docker image have as a layer to be built on top of?\nHoping that the description of the Docker images is clear now, let\u0026rsquo;s now take a look at our first Docker image. And what better to look at than the image of Ubuntu itself!?!?\nDocker Image on Hub Use this link to navigate to the Docker Hub page of the Ubuntu image. Once there, go through the \u0026lsquo;What is Ubuntu?\u0026rsquo;, and \u0026lsquo;What\u0026rsquo;s in this image?\u0026rsquo; section. As you might have read, this image is Ubuntu. We can use this image for general purpose stuff on Ubuntu.\nNow let\u0026rsquo;s go to the \u0026lsquo;Tags\u0026rsquo; section on the webpage, and see what we find there. We can see that there many tags, and the first one that appears should have the TAG \u0026lsquo;Latest\u0026rsquo;, and on it\u0026rsquo;s right, there should be a command that says: docker pull ubuntu:latest. If we look at the next tag after Latest, notice how the docker pull command changes slightly with the name of the TAG that we are referring to! Also, take a look at the size of the image. It should be around 25-30 MB. WHATTTTTTT!!!! This means that the docker image that can run Ubuntu instructions is only 30 MB in size.üôÄ\nLet\u0026rsquo;s stop for a moment here and summarize what we have seen so far:\nDocker Hub has many pre-built images ready for us to explore Almost all the images have a description about what they are and a small summary of what they contain. Some have much greater description in terms of the Environment Variables, but let\u0026rsquo;s look at it later All the pre-built images on Docker Hub have Tags, and every tag is a version of the image Every image tag has a set of instructions about how to pull it. Let\u0026rsquo;s understand what the pull command does!üêï\nDocker Pullüßó Seeing that we have a command linked to a image on Docker Hub, naturally the next step is to get our hands dirty. This helps me get out of my comfort zone, but also helps me bring a concept that I am trying to grasp much easier to understand. I hope this also works the same for youüêà\nImp. Noteüê≥: For getting our hands dirty here, it is advised to go through the installation of Docker Desktop. Personally, I like the Docker Engine with the compose tool more, but to begin with, either of the two installations should work fine.\nWith Docker installed on your system, let\u0026rsquo;s verify the docker version. This can be done by opening a terminal and typing:\ndocker --version If you see a message with version, then we are good to get into the fun part.\nIn the terminal, type the below command to check the current images that docker has on your machine:\ndocker images If you see nothing, or only see the hello-world image, then we are good to go. Let\u0026rsquo;s now run the command that we saw on Docker Hub page of Ubuntu:\ndocker pull ubuntu:latest Once you run this command, you should see something similar to this:\nlatest: Pulling from library/ubuntu 6e3729cf69e0: Pull complete Digest: sha256:27cb6e6ccef575a4698b66f5de06c7ecd61589132d5a91d098f7f3f9285415a9 Status: Downloaded newer image for ubuntu:latest docker.io/library/ubuntu:latest What docker pull does is it pulls the image from Docker Hub into your local machine. Once the above output is visible in the terminal, we can check the images again with docker images, and now we should see the ubuntu image with the latest tag in the terminal.\nThis is the way for us to pull pre-built images from Docker Hub\nDockerFileüê≥ Since Docker images are a union of layered filesystem stacked on top of each other, we can also build our own custom image that does something that we want by building it on top of another pre-built image. To build our own image, we first need to create a DockerFile, which is a configuration file that has commands that Docker uses to build our image. Let\u0026rsquo;s have a look at the terminology that the DockerFile has.\nTerminologyüìñ DockerFile is just a text document that contains a set of instructions in order that Docker has to execute to build our image. Let\u0026rsquo;s now look at some of the most used commands that we need to build our own Docker image, while the main list of commands is still available under DockerFile reference.\nFROM: This commands sets the base image that we want our own image to be built on top of. Every DockerFile should start with a FROM command, since every image is built on top of another image.\nRUN: As the name suggests, this command is used to execute a set of instructions on top of the base image that we use for our own custom image. RUN commands can be run in two ways: either in shell form, or in exec form, which means there are two ways to run commands for the RUN instruction. The shell form for RUN directly uses the instruction like RUN sh -c echo hello, while in the exec form, the same command would be run as RUN [\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;echo hello\u0026quot;]\nCOPY: This command is used to copy something from our project code inside the Docker image. The copy command needs a source location to copy from and a destination location to copy inside the Docker image.\nWORKDIR: Sets the current working directory for the Docker image, such that all the instructions that follow the after setting WORKDIR will be executed from that directory.\nCMD: This instruction is used to specify the default arguments that we want the Docker image to take when we run it. There can only be one CMD instruction in a DockerFile, and if we have multiple, then only the last one will be executed. CMD instruction works as setting default arguments when we want to run an image.\nENTRYPOINT: As CMD sets a default command, the ENTRYPOINT command can override it. However, how the command is overridden depends on the whether the shell form is used or the exec form is used. The most intuitive explanation of the interaction between CMD and ENTRYPOINT is in the Docker documentation\nWhew!!üòå That was a lot of terminology, and we have not even covered eveything from the DockerFile reference. However, we do not need to understand how each and every parameter works in order to get started. Instead, these are the most common commands that are usually inside a DockerFile while building custom images.\nLet\u0026rsquo;s now build our own Docker image by building a DockerFileü§©\nCreating a DockerFile‚úçÔ∏è If you have gone through the installation process of installing Docker, you might have come across the hello-world example of docker. But in our case, let\u0026rsquo;s redo the hello-world example in Python, but by building our own Docker image.\nFirst thing is to create a simple Python script by placing the following line inside:\nprint(f\u0026#39;Hello world from inside the Docker container!\u0026#39;) Next step is to copy the below code into a file and naming it Dockerfile:\nFROM python WORKDIR /usr/src/app COPY hello_world.py ./ CMD [\u0026#34;python\u0026#34;, \u0026#34;hello_world.py\u0026#34;] In this file, we can see the following thing:\nThe first command we write is the FROM instruction, with the python image being used. Note that if we do not mention a default tag, then the latest tag is taken as default. The second instruction is setting the WORKDIR, which is like navigating to the /usr/src/app directory inside the container. The third instruction is COPY, which selects the hello_world.py to the current working directory set by the WORKDIR command The last instruction is CMD, which sets the default command to run when the image is started as a container. Building your image‚öíÔ∏è Once the above file is created, navigate to the folder containing the file and build the image using the Dockerfile that we created in the step above. The build command is used to build an image from a particular Dockerfile by using all the instructions from inside the Dockerfile. The -t flag is used to give a name and a tag to our image, similar to the name and the tag we see on Docker Hub. Run the following command in the terminal where the Dockerfile is located:\ndocker build -t custom_image:latest . Once the above command is run, we should see something like this in the terminal:\nStep 1/4 : FROM python latest: Pulling from library/python f2f58072e9ed: Pull complete 5c8cfbf51e6e: Pull complete aa3a609d1579: Pull complete 094e7d9bb04e: Pull complete 2cbfd734f382: Pull complete aa86ac293d0f: Pull complete 4cffc9f44941: Pull complete ae2c75627c86: Pull complete 2d2b74d2f0f7: Pull complete Digest: sha256:11560799e4311fd5abcca7ace13585756d7222ce5471162cd78c78a4ecaf62bd Status: Downloaded newer image for python:latest ---\u0026gt; 539eccd5ee4e Step 2/4 : WORKDIR /usr/src/app ---\u0026gt; Running in a63f44fb58c6 Removing intermediate container a63f44fb58c6 ---\u0026gt; 266dd62fca08 Step 3/4 : COPY hello_world.py ./ ---\u0026gt; 016f934d50e5 Step 4/4 : CMD [\u0026#34;python\u0026#34;, \u0026#34;hello_world.py\u0026#34;] ---\u0026gt; Running in b38de1b256fa Removing intermediate container b38de1b256fa ---\u0026gt; 432ba341135f Successfully built 432ba341135f Successfully tagged custom_image:latest As we analyze the output of the build command, we can see the following things:\nEvery instruction starts with the Step comment, followed by the step number which is currently being executed. For example, in Step 1/4, we can see that the docker engine is pulling the image from the Docker Hub to our local machine. Every instruction that we provided in the Dockerfile is echoed first, followed by its execution hash. Once all the instructions are executed, we get the final message saying Successfully built \u0026lt;hash\u0026gt; and Successfully tagged custom_image:latest. This message means that our custom image is now built. [Bonus]Running your custom imageüèÉ Once the above commands are run in the order we specify, we can check the list of images we have on our local machine by running the following command in the terminal:\ndocker images Here, we should see our custom_image being listed amongst other images, if any. Now that we have built our custom image, it is time to run it. For now, let\u0026rsquo;s copy the following command in the terminal to run the image as a container (Don\u0026rsquo;t worry about the below line of code, we will look at it in the here):\ndocker run custom_image:latest Once we execute the above command, we should see our print message in the terminal: Hello world from inside the Docker container!\nCongratulations!!ü•≥üéâ You have successfully built your first custom image. You are already a Docker Pro!!ü§ì\nSumming Up!üí° We saw in this post how once can either pull images from the Docker Hub or create their own custom images, and run them from the terminal. The next post will now focus more on the later part of running the image once we have it on our machine.\nUntil then, Cheers!!üï∫üíÉ\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_images/","summary":"Docker Imagesüê≥ As we saw in the basics of Docker post, the base flow of every Docker container is an image. A Docker image, whether custom or pre-built, is absolutely necessary for us to be able to run anything using Docker.\nIn essence, a Docker image is a union of layered filesystem stacked on top of each other. This stands true for pre-built images as well as custom images that we might create using some pre-built image as a base.","title":"Docker Images and DockerFile"},{"content":"In the previous chapter, we saw we can use slices as references to a contiguous sequence of elements in a collection instead of the whole collection. In this chapter, we will deviate from Ownership rules and see how we can use structs to create custom data types.\nStructs In Rust, and in object-oriented programming languages, a Struct or structure is a custom data type that lets you hold multiple values in relation to it. It is like a tuple in the sense that a tuple also holds multiple values, but a tuple does not have names associated with the values. A Struct is similar to a tuple in the sense that it also holds multiple values, but it differs in the sense that it has names associated with the values.\nA struct is defined as follows:\nstruct User { active: bool, username: String, email: String, sign_in_count: u64, } and is initialized as follows:\nfn main() { let user1 = User { active: true, username: String::from(\u0026#34;someusername123\u0026#34;), email: String::from(\u0026#34;someone@example.com\u0026#34;), sign_in_count: 1, }; } Note: Syntax: When initializing a struct, the order of fields does not matter. We need curly brackets containing key-value pairs for each of the field of a struct.\nWe can extract values from a struct using the . operator followed by the key.\nNote: Design Choice: If we want to modify a field of a struct, the entire struct has to be mutable, rather than a single field.\nStructs can also be return values of functions, as shown below:\nstruct User { // defining a struct active: bool, username: String, email: String, sign_in_count: u64, } fn build_user(email: String, username: String) -\u0026gt; User { User { // returning an initialized struct email: email, // we can use shorthand syntax and just put \u0026#39;email\u0026#39; instead of \u0026#39;email: email\u0026#39; username: username, // can also use shorthand syntax here active: true, sign_in_count: 1, } } Creating a new struct by reusing values from an old struct The struct update syntax helps us reuse most of the values from a struct to create a new struct. This is useful when only have to modify a few values in the new struct.\nSuppose we have a user1 object from the User struct as follows:\nlet user1 = User { active: true, username: String::from(\u0026#34;someusername123\u0026#34;), email: String::from(\u0026#34;someone@example.com\u0026#34;), sign_in_count: 1, }; Let\u0026rsquo;s say we want to create another user that only has a different email, but the rest of the values are the same as that of user1. This can be done as follows:\nlet user2 = User { email: String::from(\u0026#34;user2email@example.com\u0026#34;), active: user1.active, // we can just get the value from user1 object username: user1.username, // we can just get the value from user1 object sign_in_count: user1.sign_in_count, // we can just get the value from user1 object }; An even better shorthand for this is as follows:\nlet user2 = User{ email: String::from(\u0026#34;user2email@example.com\u0026#34;), ..user1 // take values for the rest of the fields as defined in \u0026#39;user1\u0026#39; } Ownership of Struct Data In the above example, when we create user2, we will no longer have access to user1 object. This is because of the = operator. When we use the = operator, the value is moved from the old variable to the new field, and the field username of user1, which is a String, will transfer ownership to user2.\nOn the other hand, if both email and username fields are changed for user2, then user1 will still be valid, as the ownership of the String values will not be transferred to user2, and active and sign_in_count are both stored on Stack as their sizes are known at compile time. Boom!\nTuple Structs We can also define structs that look like tuples, but are different types. These are called tuple structs. They have no key names associated with the values, but they are different types. For example:\nstruct Color(i32, i32, i32); struct Point(i32, i32, i32); are two different tuples of type Color and Point respectively, even though they have the same number of values and the same types of values. A function that takes Color type as an argument cannot take a Point type as an argument, even though they look the same.\nHow and when to use Structs Using tuple can be useful in some scenarios where we want to link values to each other. For example, if we want to calculate the area of a rectangle, we could use a tuple as follows:\nfn main() { let rectangle = (10, 20); // tuple containing width and height compute_area(rectangle); // pass a tuple struct as an argument fn compute_area(dims: (i32, i32)) -\u0026gt; i32 { dims.0 * dims.1 } } The above implementation uses a tuple struct Rectangle, and we pass the width and the height to it together as a tuple. But what if we wanted to plot the rectangle? We would then need to keep track of which index represents the width and height. That can get messy very fast.\nUsing struct instead Instead of passing a tuple, we can improve the readiblity of the code above by creating a struct Rectangle and assigning the width and height to it as follows:\nfn main() { struct Rectangle { width: i32, height: i32, } let rect = Rectangle { width: 10, height: 20 }; compute_area(\u0026amp;rect); fn compute_area(rect: \u0026amp;Rectangle) { let rect_area = rect.width * rect.height; println!(\u0026#34;The area of the rectangle is {rect_area}\u0026#34;) } } We can see that the implementation that we have now is much easier to understand since the paremeters width and height are linked to the struct Rectangle.\nAdding more functionality to structs So far, we have not tried to print a struct object in rust. Let\u0026rsquo;s try the following to print a struct object:\nfn main() { struct Rectangle { width: i32, height: i32, } ; let rect = Rectangle { width: 10, height: 20 }; println!(\u0026#34;The rectangle is {rect}\u0026#34;, rect = rect); } When run, we should get the following error:\nerror[E0277]: `Rectangle` doesn\u0026#39;t implement `std::fmt::Display` --\u0026gt; src/main.rs:15:60 | 15 | println!(\u0026#34;The area of the rectangle is {rect}\u0026#34;, rect = rect); | ^^^^ `Rectangle` cannot be formatted with the default formatter | = help: the trait `std::fmt::Display` is not implemented for `Rectangle` = note: in format strings you may be able to use `{:?}` (or {:#?} for pretty-print) instead = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info) Okay, compiler says let\u0026rsquo;s try to print with {:?} instead. Let\u0026rsquo;s try that:\nuse std::io; fn main() { struct Rectangle { width: i32, height: i32, } let rect = Rectangle { width: 10, height: 20 }; println!(\u0026#34;The rectangle is {:?}\u0026#34;, rect); } When run, now we get another error:\nerror[E0277]: `Rectangle` doesn\u0026#39;t implement `Debug` --\u0026gt; src/main.rs:15:51 | 15 | println!(\u0026#34;The area of the rectangle is {:?}\u0026#34;, rect); | ^^^^ `Rectangle` cannot be formatted using `{:?}` | = help: the trait `Debug` is not implemented for `Rectangle` = note: add `#[derive(Debug)]` to `Rectangle` or manually `impl Debug for Rectangle` = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info) help: consider annotating `Rectangle` with `#[derive(Debug)]` | 4 | #[derive(Debug)] | The error now says Rectangle doesn't implement Debug.\nIn rust, Debug is a trait that allows us to print the data of a variable such that it is easier for us to debug. The compiler also gives us help: add '#[derive(Debug)]' to Rectangle or manually 'impl Debug for Rectangle'\nTo resolve this issue, we can modify our code as following:\nfn main() { #[derive(Debug)] // we added the Debug trait to our struct struct Rectangle { width: i32, height: i32, } let rect = Rectangle { width: 10, height: 20, }; println!(\u0026#34;The rectangle is {:?}\u0026#34;, rect); // this should now work and show the data in the struct } Run the above code and be in for a surprise!\nAttaching a method to a struct The function to compute area is very specific to rectangles, and will not work for circles or triangles. In that, we should link the compute_area function to the Rectangle struct. This would be attaching a method to the struct. Let\u0026rsquo;s see how we can do that:\nfn main() { struct Rectangle { // create struct Rectangle width: i32, height: i32, } let rect = Rectangle { // create an instance of Rectangle width: 10, height: 20, }; impl Rectangle { // start implementation block fn area(\u0026amp;self) -\u0026gt; i32 { // associate method to Rectangle struct via \u0026amp;self self.width * self.height } } println!(\u0026#34;The area of the rectangle is {}\u0026#34;, rect.area()); } We see that using the keyword impl and then the name of the struct, we are able to create a method for that struct. For the method that we create, we need to first argument to be the self keyword, so that the method knows that it is associated with the struct. We can then use the self keyword to access the values of the struct.\nImportant Note: In rust, instead of using the self keyword directly, we use the \u0026amp;self keyword to avoid taking ownership of the struct. The documentation also mentions that it is very rare that a method takes ownership of the struct, and most of the time we just use the reference of the struct as input via \u0026amp;self.\nIn rust, we can also set getters for attributes by creating methods for them. Getters are not set by default in rust, unlike in Python or other languages. When creating a getter method, we usually set the name of the method equal to the name of the attribute.\nMethods with more Parameters We can keep multiple parameters in the method, and use them as we would in any other function. We can also link multiple methods to a struct.\n","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap5/","summary":"In the previous chapter, we saw we can use slices as references to a contiguous sequence of elements in a collection instead of the whole collection. In this chapter, we will deviate from Ownership rules and see how we can use structs to create custom data types.\nStructs In Rust, and in object-oriented programming languages, a Struct or structure is a custom data type that lets you hold multiple values in relation to it.","title":"Rust Documentation: Chapter 5"},{"content":"In the previous chapter, we saw how references work in Rust when we do not directly want to transfer ownership. In this chapter, we will see how we can use slices to reference a contiguous sequence of elements in a collection instead of the whole collection.\nSlices Slices let you reference a contiguous sequence of elements in a collection rather than the whole collection. A slice is a kind of reference, so it does not have ownership.\nWhy are slices useful? Let\u0026rsquo;s take the example from the Rust documentation. We need to write a function that takes a string, and returns the first word separated by a space or the whole word if space is not found. The definition of the function would take in a string reference as we do not want to take ownership, but what should be the return type?\nIt could be the whole string, but that would mean that we are taking ownership of the string. We could return an index of the location where we see a space or the index of the last character depending on whether we could find a space. Let\u0026rsquo;s try the second approach and create a function.\nfn get_first_word(s: \u0026amp;String) -\u0026gt; usize { let bytes = s.as_bytes(); // convert string to array of bytes for (i, \u0026amp;item) in bytes.iter().enumerate() { // iterate over the array of bytes by index if item == b\u0026#39; \u0026#39; { // match the byte with the space character return i; // return index of the space character, function ends if found } } s.len() // return the length, i.e., index of the last character of string, function ends } Even though our implementation is correct and would work, we still have one problem. The index we derive from the function is only valid as long as the input word itself does not change. What if the string passed as reference to s changes in value or is dropped altogether? Then the index we return would no longer be valid and would point to a different value. This can be seen in the following example.\nfn main() { let mut some_string = String::from(\u0026#34;Hey there!\u0026#34;); // create a variable let first_word = get_first_word(\u0026amp;some_string); // returns 3, index of space character some_string.clear(); // string is cleared, but first_word variable still contains the index } We can see from the above example that even if the input attribute to the function is cleared, the value that the function holds is not cleared, but becomes invalid in comparison to the changed string. This is where slices come in.\nString Slices String slices are references to parts of string that we can create. It can be created as follows:\nlet s = String::from(\u0026#34;Hello World!\u0026#34;); let first_slice = \u0026amp;s[0..5]; // only takes the first 5 characters let second_slice = \u0026amp;s[6..11]; // takes the last 5 characters, the word \u0026#39;World\u0026#39; Internally, a slice stores the start index and the length of the slice to store defined by the last index.\nUsing the above, let\u0026rsquo;s try to rewrite our initial function of getting the first word of a string. String slice references are represented as \u0026amp;str in Rust.\nfn get_first_word(s: \u0026amp;String) -\u0026gt; \u0026amp;str { let bytes = s.as_bytes(); // convert string to array of bytes for (i, \u0026amp;item) in bytes.iter().enumerate() { // iterate over the array of bytes by index if item == b\u0026#39; \u0026#39; { // match the byte with the space character return \u0026amp;s[0..i]; // return the slice of the string from 0 to index of space character } } \u0026amp;s[..]; } Even though much of the logic of the code remains the same to our initial implementation of the get_first_word function, we now return a string slice which will remain valid if the input string changes. Moreover, the compiler will make sure that the string slice returned is valid and does not point to an invalid index.\nIf we now try to drop the string after the function call, we will get an error as the string slice returned as follows:\nfn main() { let s = String::from(\u0026#34;Hello World!\u0026#34;); let first_word = get_first_word(\u0026amp;s); s.clear(); // compiler will throw an error as the string slice returned is invalid } If we run the above code, we will get the following error:\n$ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0502]: cannot borrow `s` as mutable because it is also borrowed as immutable --\u0026gt; src/main.rs:18:5 | 16 | let word = first_word(\u0026amp;s); | -- immutable borrow occurs here 17 | 18 | s.clear(); // error! | ^^^^^^^^^ mutable borrow occurs here 19 | 20 | println!(\u0026#34;the first word is: {}\u0026#34;, word); | ---- immutable borrow later used here For more information about this error, try `rustc --explain E0502`. error: could not compile `ownership` due to previous error This is coherent with the borrowing references we saw in Chapter 4 - References, where we saw that if we have an immutable reference to something, we cannot also take a mutable reference. The s.clear() call will take a mutable reference to s to clear the string out, but this is not allowed in Rust. Neat!\nString Literals are Slices When we create a string literal, we are actually creating a string slice. For example, \u0026quot;Hello World!\u0026quot; is a string literal, and its type is \u0026amp;str. This is because string literals are stored in the binary of the program, and are therefore immutable. This is why we cannot add to a string literal, but we can add to a String type.\nOther slice types We can also create slices on array types in rust just as we created them for string types. For example, we can create a slice on an array of integers as follows:\nlet a = [1, 2, 3, 4, 5]; let slice = \u0026amp;a[1..3]; // slice of array from index 1 to 3 \u0026amp;assert_eq!(slice, \u0026amp;[2, 3]); Summary All the concepts we have seen in Chapter 4, 5 and 6 are very important to understand the concept of ownership, borrowing, and memory safety in rust. We will see more of these concepts in the next chapter, where we will see how to use these concepts to create a program that is memory safe and does not have any memory leaks.\nLet us now look at the next chapter on Struct in Rust!\n","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap4-slices/","summary":"In the previous chapter, we saw how references work in Rust when we do not directly want to transfer ownership. In this chapter, we will see how we can use slices to reference a contiguous sequence of elements in a collection instead of the whole collection.\nSlices Slices let you reference a contiguous sequence of elements in a collection rather than the whole collection. A slice is a kind of reference, so it does not have ownership.","title":"Rust Documentation: Chapter 4 - Slices"},{"content":"In the previous chapter, we saw how ownership works in Rust. The main drawback we saw was that for functions, the return value changes ownership and the original variable is no longer usable. In this chapter, we will look at a continuation of ownership, i.e. references.\nReferences Instead of passing variables to functions, we can pass references to functions. reference is like a pointer we can follow to get to the data. Unlike a pointer, a reference is guaranteed to point to valid data for the life of that reference.\nIn rust, references can be used as follows:\nfn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let len = calculate_length(\u0026amp;s1); println!(\u0026#34;The length of \u0026#39;{}\u0026#39; is {}.\u0026#34;, s1, len); // here s is valid as we only pass its reference } fn calculate_length(s: \u0026amp;String) -\u0026gt; usize { // we need to pass the type of the reference s.len() } In the above function, passing the ampersand String instead of String is called referencing and it allows us to refer to a value without taking ownership of it. Since the value s in the function is only referenced and not owned, it will not be dropped when the function ends, and would thus still be valid.\nThis action of creating a reference and passing it to a function that accepts a reference is called borrowing, since we are only borrowing a value and not taking ownership of it! Neat!!!!\nModifying borrowed values What were to happen if we try to modify a value we have borrowed? For example, in the function below, we try to modify the reference that is passed to the function:\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); update_string(\u0026amp;s); fn update_string(s: \u0026amp;String) { s.push_str(\u0026#34;, world!\u0026#34;); } } If we try to run the above code, we will get the following error:\n$ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0596]: cannot borrow `*some_string` as mutable, as it is behind a `\u0026amp;` reference --\u0026gt; src/main.rs:8:5 | 7 | fn change(some_string: \u0026amp;String) { | ------- help: consider changing this to be a mutable reference: `\u0026amp;mut String` 8 | some_string.push_str(\u0026#34;, world\u0026#34;); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `some_string` is a `\u0026amp;` reference, so the data it refers to cannot be borrowed as mutable For more information about this error, try `rustc --explain E0596`. error: could not compile `ownership` due to previous error The error is pretty self-explanatory. We cannot modify a value that we have borrowed. This is because when we pass a reference to a function, we are only allowed to read the value, not modify it. This is called immutable borrowing. This is also the same behaviour that we have seen for variables that are immutable by default in Chapter 3.\nMutable References Just as we had mutable variables, we can also have mutable references. We can create a mutable reference by using \u0026amp;mut instead of \u0026amp;:\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); update_string(\u0026amp;mut s); fn update_string(s: \u0026amp;mut String) { s.push_str(\u0026#34;, world!\u0026#34;); } } In the above implementation, we pass the \u0026amp;mut s to the function as reference instead of \u0026amp;s. Next, we also pass the \u0026amp;mut String to the function instead of \u0026amp;String, implying that we are passing a mutable reference to the function.\nMajor restriction: We can only have one mutable reference to a particular piece of data in a particular scope. In short, there can only be a single mutable reference to a particular variable that we can use.\nFor example, the following code will not compile:\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;mut s; let r2 = \u0026amp;mut s; println!(\u0026#34;{}, {}\u0026#34;, r1, r2); } If we run the above code, it will raise the following error:\n$ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0499]: cannot borrow `s` as mutable more than once at a time --\u0026gt; src/main.rs:5:14 | 4 | let r1 = \u0026amp;mut s; | ------ first mutable borrow occurs here 5 | let r2 = \u0026amp;mut s; | ^^^^^^ second mutable borrow occurs here 6 | 7 | println!(\u0026#34;{}, {}\u0026#34;, r1, r2); | -- first borrow later used here For more information about this error, try `rustc --explain E0499`. error: could not compile `ownership` due to previous error Since we are trying to create two references r1 and r2 to the same variable s, the compiler will throw an error. The error is because we are borrowing the same variable a second time before the scope of the first variable is not finished.\nIf we were to change the above code to the following, it will run without this error:\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;mut s; println!(\u0026#34;The value of r1 is {r1}\u0026#34;); let r2 = \u0026amp;mut s; println!(\u0026#34;The value of r1 is {r2}\u0026#34;); } In this case, we are first ending the scope of r1 when we call print, and we are then creating a second reference r2 to the variable s. This is allowed by the compiler.\nResticting multiple mutable references: The main advantage for restricting multiple mutable references is that the compiler does not have data races at compile time. A data race is similar to a race condition and happens when these three behaviors occur:\nTwo or more pointers access the same data at the same time. At least one of the pointers is being used to write to the data. There‚Äôs no mechanism being used to synchronize access to the data. We can also use {} to scope a mutable reference such that there is no conflict between two mutable references:\nfn main() { let mut s = String::from(\u0026#34;Hello\u0026#34;); { let r1 = \u0026amp;mut s; println!(\u0026#34;The value of r1 is {}\u0026#34;, r1); } // scope of mutable reference is finished, and a new variable with mutable reference can be created let r2 = \u0026amp;mut s; println!(\u0026#34;The value of r2 is {}\u0026#34;, r2); } The above code will also compile, since the scope of the first mutable reference r1 is finished before we create the second mutable reference r2 by using {}.\nScope matters for mutable and immutable references! We can have multiple immutable references from a variable, since by nature, immutable references cannot change any value, and can be looked at as a read-only reference. However, we cannot put an mutable reference before the scope of the immutable reference is finished, since the mutable reference can change the value of the variable, and thus, the immutable reference will not be valid anymore.\nThis can be seen clearly from the below example:\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;s; // no problem, since immutable reference used let r2 = \u0026amp;s; // no problem, since immutable reference used let r3 = \u0026amp;mut s; // BIG PROBLEM, mutable reference used before immutable references are finished println!(\u0026#34;{}, {}, and {}\u0026#34;, r1, r2, r3); // will not compile } Running the above code will raise the following error:\n$ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0502]: cannot borrow `s` as mutable because it is also borrowed as immutable --\u0026gt; src/main.rs:6:14 | 4 | let r1 = \u0026amp;s; // no problem | -- immutable borrow occurs here 5 | let r2 = \u0026amp;s; // no problem 6 | let r3 = \u0026amp;mut s; // BIG PROBLEM | ^^^^^^ mutable borrow occurs here 7 | 8 | println!(\u0026#34;{}, {}, and {}\u0026#34;, r1, r2, r3); | -- immutable borrow later used here For more information about this error, try `rustc --explain E0502`. error: could not compile `ownership` due to previous error As we can see, the compiler will not allow us to create a mutable reference r3 before the immutable references r1 and r2 are finished. This is because the mutable reference r3 can change the value of the variable s, and thus, the immutable references r1 and r2 will not be valid anymore.\nHowever, the below code is valid and will compile:\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;s; // no problem, read-only let r2 = \u0026amp;s; // no problem, read-only println!(\u0026#34;{} and {}\u0026#34;, r1, r2); // variables r1 and r2 will not be used after this point let r3 = \u0026amp;mut s; // no problem even if modified println!(\u0026#34;{}\u0026#34;, r3); } Dangling references For languages with pointers, it is possible that a reference can point to a location that is given to another variable, or free some other variables memory by mistake. In rust, the compiler never lets us create dangling references to a variable. If we have a reference to some data, the compiler will make sure that the data does not go out of scope before the reference is out of scope.\nLet\u0026rsquo;s look at the below example to see how rust prevents us creating a dangling reference.\nfn main() { let some_reference = dangle(); // is a reference to a return value of a function fn dangle() -\u0026gt; \u0026amp;String { let s = String::from(\u0026#34;hello\u0026#34;); // s comes into scope at this line \u0026amp;s // create a reference to s and return it } // the function finishes and s goes out of scope after this line, so the reference has nothing to // point to } Running the above, we get the following error:\nerror[E0106]: missing lifetime specifier --\u0026gt; src/main.rs:6:20 | 6 | fn dangle() -\u0026gt; \u0026amp;String { | ^ expected named lifetime parameter | = help: this function\u0026#39;s return type contains a borrowed value, but there is no value for it to be borrowed from help: consider using the `\u0026#39;static` lifetime | 6 | fn dangle() -\u0026gt; \u0026amp;\u0026#39;static String { | +++++++ The error says that this functions's return type contains a borrowed value, but there is no value for it to be borrowed from. This is because the variable s goes out of scope after the function dangle finishes, and thus, the reference \u0026amp;s has nothing to point to.\nInstead of returning a reference in the above function, we need to return s directly, and take ownership of the variable s in the function dangle:\nWe can see how a plan comes together in rust with ownership and scope.\nIn the next chapter, we will look at a different kind of reference, called slice.\n","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap4-references/","summary":"In the previous chapter, we saw how ownership works in Rust. The main drawback we saw was that for functions, the return value changes ownership and the original variable is no longer usable. In this chapter, we will look at a continuation of ownership, i.e. references.\nReferences Instead of passing variables to functions, we can pass references to functions. reference is like a pointer we can follow to get to the data.","title":"Rust Documentation: Chapter 4 - References"},{"content":"In the previous chapter, we saw how we can use data types, functions, and control flow in rust. In this chapter, we will look at the most unique feature of rust - ownership.\nOwnership Ownership enables Rust to make memory safety guarantees without needing a garbage collector, so it‚Äôs important to understand how ownership works. In this chapter, we‚Äôll talk about ownership as well as several related features: borrowing, slices, and how Rust lays data out in memory.\nStack and Heap In stack, it is easier to store objects that have a known size at compile time. The stack stores values in the LIFO order. In heap, it is easier to store objects that have an unknown size at compile time or a size that might change. The heap stores values in any order, wherein the compiler looks for a place to store the data.\nPushing to the stack is faster than allocating on the heap because the allocator never has to search for a place to store new data; that location is always at the top of the stack. Comparatively, allocating space on the heap requires more work because the allocator must first find a big enough space to hold the data and then perform bookkeeping to prepare for the next allocation.\nWhen we call a function, all the parameters of the function are pushed onto the stack. When the function is over, the parameters are popped off the stack. This is why the size of all the parameters of a function must be known at compile time. Usually, all vairables that have a known data type, i.e., i32, u32, f32, etc. are stored on the stack.\nIn heap, we usually keep a pointer to the location in memory where the data is stored.\nOwnership Rules In rust, there are a few rules that the compiler checks to ensure memory safety. These are:\nEach value in Rust has an owner. There can only be one owner at a time. When the owner goes out of scope, the value will be dropped. Memory and Allocation In rust, when we take a String type, we might not always know how much memory we need to allocate for it, since it is possible to later change the value that the String type holds. We can see this in an example below:\nlet mut s = String::from(\u0026#34;hello\u0026#34;); s.push_str(\u0026#34;, world!\u0026#34;); // push_str() appends a literal to a String println!(\u0026#34;{}\u0026#34;, s); // This will print `hello, world!` We can see that we can add string literals to rust strings. However, this type of operation is not possible for string literals. This main difference comes because of the way rust handles memory and allocation for the String type.\nWith the String type, in order to support a mutable, growable piece of text, we need to allocate an amount of memory on the heap, unknown at compile time, to hold the contents. This means:\nThe memory must be requested from the memory allocator at runtime. We need a way of returning this memory to the allocator when we‚Äôre done with our String. The String::from function does all the memory allocation for us. However, once we have requested memory, we need to keep track of when that memory needs to be freed up.\nIn rust, the memory is automatically returned once the variable that owns it goes out of scope. This can be seen in the example below:\n{ let s = String::from(\u0026#34;hello\u0026#34;); // s is valid from this point forward // do stuff with s } // this scope is now over, and s is no longer valid When a variable goes out of scope, the drop function is called that frees up the memory.\nVariable and Data Interaction with Move In rust, we can assign a String to a different variable using let as follows:\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; When we do this, we expect s2 to also contain the contents of the String that s1 contains. However, this is not the case.\nA String is made up of three parts: a pointer to the memory that holds the contents of the string, a length, and a capacity. This group of data is stored on the stack. The memory that the pointer refers to is stored on the heap.\nThis can be seen in the below image:\nWhen we assign s1 to s2, the String data is copied, meaning we copy the pointer, the length, and the capacity that are on the stack. We do not copy the data on the heap that the pointer refers to.\nIn short, this is what happens\nWe can see from the above image that there is not a new copy of the data that is created when we assign s1 to s2. In short, rust does not create a deep copy when we assign one variable to another.\nDouble free memory error Now that we have s1 and s2 pointing to the same location in memory, this can potentially cause problems. For example, when both variables go out of scope, they will both try to free the same memory. This is known as a double free error.\nTo avoid such errors, rust considers that once we assign s1 to s2, s1 is no longer valid. This is known as a move in rust. This can be seen as a type of shallow copy, wherein s2 does not copy the data from s1, but instead, it takes ownership of the data that s1 was pointing to. s1 was moved into s2.\nImportant Note: rust does not create deep copy of a variable by default. To create a deep copy, we need to use the clone method.\nClone method To make sure that a deep copy is created when we take s1 and assign it to s2, we can use the clone method. This copies the data from the stack (which is the pointer, length, and capacity) as well as the data from the heap into the new variable s2. We can clone a variable as follows:\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); Copy trait By default, for variables for which the size is fixed at compile time, like integers, booleans, are stored on the stack. When these variables are assigned to new variables, instead of the move operation, a copy operation is performed. The copy operation copies the value of the original variable to the new variable, while still keeping both variables valid. While this is a contradiction to the move method that rust uses, it is a design choice since it is easier to copy data from the stack than from the heap.\nBy default, the following types implement the Copy trait:\nAll the integer types, such as u32. The boolean type, bool. The floating point types, such as f64. The character type, char. Tuples, if they only contain types that also implement Copy. For example, (i32, i32) implements Copy, but (i32, String) does not. Ownership and Functions When we pass a variable to a function, the ownership of the variable is either moved or copied to the function, based on the type of variable that the function uses. This can be seen in the below example:\nfn main() { let string_variable = String::from(\u0026#34;hello\u0026#34;); // \u0026#39;string_variable\u0026#39; comes into scope show_string(string_variable); // \u0026#39;string_variable\u0026#39; is moved into the function // \u0026#39;string_variable\u0026#39; is no longer valid let x = 5; // \u0026#39;x\u0026#39; comes into scope show_number(x); // \u0026#39;x\u0026#39; is copied into the function instead of moved, and is still valid after the function call // \u0026#39;x\u0026#39; is still valid after the function call fn show_string(string_variable: String) { // \u0026#39;string_variable\u0026#39; comes into scope println!(\u0026#34;{}\u0026#34;, string_variable); } // \u0026#39;string_variable\u0026#39; goes out of scope and the memory is freed via \u0026#39;drop\u0026#39; fn show_number(x: i32) { // \u0026#39;x\u0026#39; comes into scope println!(\u0026#34;{}\u0026#34;, x); } // \u0026#39;x\u0026#39; goes out of scope, but nothing special happens, since there is no \u0026#39;drop\u0026#39; to be done } Ownership in return values and scopes Ownership works the same way for function return values as it does for variables. When a function returns a value, the ownership of the value is either moved or copied to the variable that is receiving the return value. This can be seen from this example:\nfn main() { let s1 = gives_ownership(); // gives_ownership moves its return // value into s1 let s2 = String::from(\u0026#34;hello\u0026#34;); // s2 comes into scope let s3 = takes_and_gives_back(s2); // s2 is moved into // takes_and_gives_back, which also // moves its return value into s3 } // Here, s3 goes out of scope and is dropped. s2 was moved, so nothing // happens. s1 goes out of scope and is dropped. fn gives_ownership() -\u0026gt; String { // gives_ownership will move its // return value into the function // that calls it let some_string = String::from(\u0026#34;yours\u0026#34;); // some_string comes into scope some_string // some_string is returned and // moves out to the calling // function } // This function takes a String and returns one fn takes_and_gives_back(a_string: String) -\u0026gt; String { // a_string comes into // scope a_string // a_string is returned and moves out to the calling function } Conclusions The ownership of a variable follows the same pattern every time: assigning a value to another variable moves it. When a variable that includes data on the heap goes out of scope, the value will be cleaned up by drop unless ownership of the data has been moved to another variable.\nDrawbacks: Functions that move ownership of variables can be cumbersome. For example, if we want to use a variable after it has been passed to a function, we cannot do so, since the variable is no longer valid. To overcome this, we can use references, which is explained in the next chapter.\n","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap4/","summary":"In the previous chapter, we saw how we can use data types, functions, and control flow in rust. In this chapter, we will look at the most unique feature of rust - ownership.\nOwnership Ownership enables Rust to make memory safety guarantees without needing a garbage collector, so it‚Äôs important to understand how ownership works. In this chapter, we‚Äôll talk about ownership as well as several related features: borrowing, slices, and how Rust lays data out in memory.","title":"Rust Documentation: Chapter 4 - Ownership"},{"content":"In the previous chapter, we built a simple guessing game. Now, we will learn more about variables, data types, mutability, and control flow in Rust\nVariables and Mutability In Rust, we define variables with let keyword. However, variables by default are not mutable in Rust. This means that once a variable is defined, it cannot be changed. To make a variable mutable, we use the mut keyword after the let keyword. Below is an example of mutable and immutable variables.\nfn main() { let x = 5; // immutable variable let mut y = 6; // mutable variable If we try to reassign value to the variable x above, the Rust compiler will NOT like it! Let\u0026rsquo;s try.\nfn main() { let x = 5; //immutable variable x = 6; } Try running the above code, and we should get the following:\nerror[E0384]: cannot assign twice to immutable variable `x` --\u0026gt; src/main.rs:4:5 | 2 | let x = 5; | - | | | first assignment to `x` | help: consider making this binding mutable: `mut x` 3 | println!(\u0026#34;The value of x is {x}\u0026#34;); 4 | x = 6; | ^^^^^ cannot assign twice to immutable variable Even if the compiler does not like what we did, it does not hate us!(unlike the C compiler, wha whaaaat!!!!) We can see that the issue is very nicely printed out for us.\nSimilarly, we can reassign any other value to the variable y from the above example as follows:\nfn main() { let mut y = 6; y = 7 println!(\u0026#34;The value of y is {y}\u0026#34;) } If you build and run the above code, you should see that the value of y is 7.\nConstants In rust, constants are always immutable by default. We define constants using the const keyword, instead of the let keyword. Trying to make a constant defined with const mutable, as seen in below code, would result in the following error:\nfn main() { const mut MAX_POINTS: u32 = 100_000; MAX_POINTS = 100_001; } error: const globals cannot be mutable --\u0026gt; src/main.rs:4:11 | 4 | const mut MAX_POINTS: u32 = 100_000; | ----- ^^^ cannot be mutable | | | help: you might want to declare a static instead: `static` So, in conclusion, we cannot make constants mutable in Rust.\nShadowing We can shadow a variable by using the same variable name as the previous variable. This is different from mutability. Let\u0026rsquo;s see an example:\nfn main() { let x = 5; let x = x + 1; let x = x * 2; println!(\u0026#34;The value of x is {x}\u0026#34;); } Also, shadowing is different that using mut variables, since for mut variables, we can ignore the let keyword, but for shadowing, we have to use the let keyword. Also, if we plan to change the datatype of the variable we are shadowing, we need to explicitly mention the new datatype.\nKey Points\nVariables are immutable by default in Rust If we want immutable variables, we use the mut keyword after the let keyword By strict nature, const variables, i.e., constants, are immutable in Rust Shadowing is different that using a mut variable, since if we shadow a variable again, we need to use the -let keyword again. If we change the datatype of the variable we are shadowing, we need to explicitly mention the new datatype. Data Types In rust, every value has a data type. Data types are the typical data types that we see in other programming languages, and they are as follows:\nScalar Types Integers Floating-Point Numbers Booleans Characters Integer Types Integer types as signed and unsigned, i.e., can range from negative to positive values, and only positive values, respectively. They are represented as either i32 for signed integers, or u32 for unsigned integers. Full reference can be found here.\nFloating-Point Types There are only two floating point types in Rust, f32 and f64. The default type is f64, since it is faster than f32 on modern CPUs.\nImportant Note: When performing mathematical operations, we need to be careful about the data types we are using. By default, mathematical operations in rust do not convert floating point numbers to return floats. For example, an operation 2/3 would return 0, since both 2 and 3 are integers. To get the correct result, we need to explicitly convert one of the numbers to a float, as follows: 2.0/3 or 2/3.0 or 2.0/3.0.\nBoolean Type Boolean types in Rust are represented as bool, and can have two values, true or false.\nCharacter Type Most primitive alphabetic type. Characters are always specified using single quotes, as follows: let c = 'z'.\nCompound Types These data types are used to combine multiple values into a one type. There are only two compound types in Rust: tuples and arrays.\nTuples Can have multiple data types clubbed into one tuple. Type annotation is optional when creating a tuple, but useful.\nTo get the values out from a tuple in rust, we can either unzip the tuple, or use . operator with the index.\nArrays Arrays must have all elements from the same data type. Arrays in rust have a fixed size, so we cannot append to arrays, instead we append to vectors, which we will see in a later chapter.\nAlso, arrays are good when we want to store the data on stack rather than heap, since they always have a fixed size.\nIn rust, arrays should be defined as follows:\nlet a: [i32; 5] = [1, 2, 3, 4, 5]; Elements from array in rust are accessed as they are in Python, via the [index] operator. If we try to access an invalid index, the compiler panics and we usually get a helpful error message.\nFunctions In rust, functions are defined with fn keyword, followed by the name of the function, and then the parameters. The return type of the function is specified after the -\u0026gt; operator. If the function does not return anything, we can omit the return type.\nIn rust, the function signatures must have a data type. This is because the compiler needs to know the size of the return type at compile time. This can be seen in this example:\nfn main() { print_labeled_measurement(5, \u0026#39;h\u0026#39;); } fn print_labeled_measurement(value: i32, unit_label: char) { println!(\u0026#34;The measurement is: {value}{unit_label}\u0026#34;); } Expressions and Statements In rust, expressions and statements are different.\nStatements are instructions that perform some action and do not return a value. Expressions evaluate to a resultant value. let y = 6; is a statement, as it is only assigning a value to the variable y.\n{ let x = 3; x + 1 } // This is an expression, since it returns the value \u0026#39;x + 1\u0026#39; We can return early from a function using the return keyword in rust. However, even without the return keyword, the last expression in a function is returned implicitly. If we have a return type, its type is to given in the function signature as follows:\nfn five() -\u0026gt; i32 { 5 } fn main() { let x = five(); println!(\u0026#34;The value of x is: {x}\u0026#34;); } Control Flow Most common constructs are the if, while, and for loops. They are all expressions, as they typically return a value at the end of their execution.\nIf Expressions Only requirement is that the condition that is being checked must be a bool type. So, we cannot have a conditional block like this in rust:\nfn main() { let number = 3; if number { println!(\u0026#34;number was three\u0026#34;); } } The above code block would raise an error in rust, as the condition if number is not a bool type.\nUsing if in let statements In rust, we can use if in let statements as follows:\nfn main() { let condition = true; let number = if condition { 5 } else { 6 }; println!(\u0026#34;The value of number is: {number}\u0026#34;); } This is a valid assignment (statement) in rust, as we assign a value based on a condition. However, we need to make sure that the return value of the conditional is of the same data type, otherwise the compiler will throw an error. For example, this is not a valid expression using if blocks:\nfn main() { let condition = true; let number = if condition { 5 } else { \u0026#34;six\u0026#34; }; println!(\u0026#34;The value of number is: {number}\u0026#34;); } The above would throw an error, as one type is of integer and another is of string type.\nLooping your code In rust, we can make loops using the loop, while, and for keywords.\nloop keyword Executes forever, until user stops the program manually. We can also use break keyword to break out of the loop.\nWe can also assign loop labels in rust to know which loop is being executed. When breaking out of a loop, we can then use the break keyword with the loop label to stop execution. It is mandatory to have the loop labels starting with the ' character to be able to use them in break statements.\nfn main() { let mut count = 0; \u0026#39;counting_up: loop { println!(\u0026#34;count = {count}\u0026#34;); let mut remaining = 10; loop { println!(\u0026#34;remaining = {remaining}\u0026#34;); if remaining == 9 { break; } if count == 2 { break \u0026#39;counting_up; } remaining -= 1; } count += 1; } println!(\u0026#34;End count = {count}\u0026#34;); } while keyword The while keyword works just like the if keyword, wherein the code is executed until it reaches a false condition.\nfor keyword The for keyword is used to iterate over a collection of items. For example, we can iterate over a range of numbers.\nImportant Note: In for conditions, the range over which we an element to loop over is specified with the syntax (start..end), where start is inclusive and end is exclusive. For example, for n in (1..4) will iterate over the numbers 1, 2, 3.\nConclusion In this chapter, we learned about the basic data types in rust, and how to use them. We also learned about the if expressions, and how to use them in let statements. We also learned about the loop, while, and for keywords, and how to use them to iterate over a collection of items.\n","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap3/","summary":"In the previous chapter, we built a simple guessing game. Now, we will learn more about variables, data types, mutability, and control flow in Rust\nVariables and Mutability In Rust, we define variables with let keyword. However, variables by default are not mutable in Rust. This means that once a variable is defined, it cannot be changed. To make a variable mutable, we use the mut keyword after the let keyword.","title":"Rust Documentation: Chapter 3"},{"content":"Programming a Guessing Game üé≤ In the previous chapter, we learned about the basics of Rust. In this chapter, we will learn about the basics of Rust by building a simple guessing game.\nSetting up the project We will use the Cargo package manager to create a new project called guessing_game. We can create a new project using the following command:\ncargo new guessing_game This creates a new project called guessing_game in the current directory. The Cargo package manager creates a new directory with the following structure:\nguessing_game ‚îú‚îÄ‚îÄ Cargo.toml ‚îî‚îÄ‚îÄ src ‚îî‚îÄ‚îÄ main.rs The Cargo.toml file contains the metadata of the project. The src directory contains the source code of the project. The main.rs file contains the main function of the project. As we saw in the previous chapter, the Cargo package manager uses the main.rs file as the entry point of the project. The Cargo package manager uses the Cargo.toml file to manage the dependencies of the project.\nGuessing game code The full code for the guessing game, which is in the main.rs file, looks as follows:\nuse std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); loop { println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: i32 = match guess.trim().parse() { Ok(num) =\u0026gt; num, Err(_) =\u0026gt; { println!(\u0026#34;This is not expected. Please enter an integer\u0026#34;); continue; }, }; println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; { println!(\u0026#34;You win! You are the guessing game champion!\u0026#34;); break; }, } } } Much of the code looks like mumbo jumbo for now, but we will break it down in pieces.\nBreakdown of the above code The use keyword is used to import the io module from the standard library. The io module contains the stdin function which is used to read the input from the user. The stdin function returns an instance of the Stdin type. The Stdin type implements the Read trait. The Read trait defines the read_line method which is used to read a line from the Stdin type.\nNOTE: Traits are similar to interfaces in other languages. They define the methods that a type must implement. We will learn more about traits in a later chapter.\nPoints to remember:\nThe main function is the entry point of the program.\nThe println! macro is used to print the string to the standard output. The println! macro is similar to the printf function in C or the print function in Python. The println! macro is a macro because it is prefixed with an exclamation mark. We will learn more about macros in a later chapter.\nThe let keyword is used to create a new variable.\nThe mut keyword is used to make the variable mutable.\nThe String::new function is used to create a new empty string. The String type is a string type provided by the standard library. The String type is a growable, UTF-8 encoded string.\nHowever, we still need a way to read the input from the user. The read_line method takes the input from the user and stores it in the guess variable. The read_line method takes the input as a mutable reference.\nThe \u0026amp; symbol is used to create a reference. The \u0026amp;mut symbol is used to create a mutable reference.\nThe read_line method returns a Result type. The Result type is an enum which has two variants: Ok and Err. The Ok variant indicates that the operation was successful. The Err variant indicates that the operation failed. The expect method is used to handle the Err variant. The expect method takes a string as an argument. If the Result type is Ok, the expect method returns the value inside the Ok variant. If the Result type is Err, the expect method prints the string passed to it and exits the program. If we don\u0026rsquo;t call the expect method, the program will compile but will throw a warning.\n$ cargo build Compiling guessing_game v0.1.0 (file:///projects/guessing_game) warning: unused `Result` that must be used --\u0026gt; src/main.rs:10:5 | 10 | io::stdin().read_line(\u0026amp;mut guess); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: `#[warn(unused_must_use)]` on by default = note: this `Result` may be an `Err` variant, which should be handled warning: `guessing_game` (bin \u0026#34;guessing_game\u0026#34;) generated 1 warning Finished dev [unoptimized + debuginfo] target(s) in 0.59s The Rust compiler is smart enough to detect that the Result type returned by the read_line method is not being used. The Rust compiler throws a warning to let us know that we are not handling the Err variant of the Result type.\nPhew! That was a lot of information. Take a look at the code again and make sure we can understand the code with the new information that we have learned.\nBuilding and Running the code We can run the code using the following command:\ncargo run Key takeaways:\ncargo run will build and run the code, while cargo build will only build an executable in the target/debug directory. cargo run is useful when we are developing the code. cargo run will compile the code and run the executable every time we make a change to the code. cargo build is useful when we are deploying the code. cargo build will compile the code and create an executable. Once run, the code will print the following output:\n$ cargo run Compiling guessing_game v0.1.0 (file:///projects/guessing_game) Finished dev [unoptimized + debuginfo] target(s) in 0.59s Running `target/debug/guessing_game` Guess the number! Please input your guess. 5 You guessed: 5 We can see that we can now take an input from the user. However, we still need to generate a random number with which the comparison for the user input has to be done. This random number generator functionality can be implemented smoothly by using cargo.\nGenerating a random number With cargo, we have the option to get crates. Crates are packages of Rust code that we can use in our project. We can get a crate by adding the crate name and the version number to the Cargo.toml file. The Cargo package manager will download the crate and add it to the Cargo.lock\nFor our case, we need to add the rand crate to the Cargo.toml file. The rand crate is a crate that provides random number generation functionality. To add the rand crate to the Cargo.toml file, we need to add the following line to the Cargo.toml file:\n[dependencies] rand = \u0026#34;0.8.5\u0026#34; The documentation of the rand crate can be found here.\nIf you build the project now with cargo build, we should see that the rand create is being fetched and added to the Cargo.lock file.\n$ cargo build Updating crates.io index Downloading crates ... Downloaded rand v0.8.5 Downloaded 1 crate (1.1 MB) in 0.75s Compiling rand v0.8.5 Compiling guessing_game v0.1.0 (file:///projects/guessing_game) Finished dev [unoptimized + debuginfo] target(s) in 1.88s However, if you run it again, we will not see the above output. cargo will check the Cargo.lock file to see if the dependencies have changed. If the dependencies have not changed, cargo will not fetch the dependencies again. This is useful when we are deploying the code, since we can be sure that the dependencies will not change when we deploy the code, and we will deploy the code with the same dependencies that we were using while developing the code.\nGenerating Random Number for our game Now that we have the rand crate, we can use it to generate a random number. We can use the gen_range method of the rand crate to generate a random number. The gen_range method takes two arguments: the lower bound and the upper bound. The gen_range method will generate a random number between the lower bound and the upper bound.\nuse std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); println!(\u0026#34;You guessed: {}\u0026#34;, guess); } If you run the code now, you will see that the code will generate a random number between 1 and 101, and will print it to the console.\n$ cargo run Compiling guessing_game v0.1.0 (file:///projects/guessing_game) Finished dev [unoptimized + debuginfo] target(s) in 1.02s Running `target/debug/guessing_game` Guess the number! The secret number is: 42 Please input your guess. 5 You guessed: 5 Now we see that a random number is being generated. However, we still need to compare the user input with the random number. We will do this in the next section.\nComparing the user input with the random number We can compare the user input with the random number using the cmp method.\nPoints to remeber:\nThe cmp method takes a reference to the value that we want to compare with. The cmp method returns an Ordering type. The Ordering type is an enum that can have three values: Less, Greater, and Equal. The cmp method compares the value that we are calling the method on with the value that we pass as an argument to the cmp method. If the value that we are calling the method on is less than the value that we pass as an argument to the cmp method, the cmp method will return the Less variant of the Ordering type. If the value that we are calling the method on is greater than the value that we pass as an argument to the cmp method, the cmp method will return the Greater variant of the Ordering type. If the value that we are calling the method on is equal to the value that we pass as an argument to the cmp method, the cmp method will return the Equal variant of the Ordering type. We can use the match expression to handle the Ordering type returned by the cmp method. The match expression is similar to the switch statement in other languages. The match expression takes a value as an argument and compares the value with the patterns that we specify in the match expression. If the value matches the pattern, the code that is associated with the pattern will be executed. If the value does not match any of the patterns, the match expression will throw an error. use std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; println!(\u0026#34;You win! You are the guessing game champion!\u0026#34;), } } If you run the code now, you will see that the code will not compile.\nPoints to remember: The reason for this is that we are trying to compare a String type with an i32 type. We can fix this by converting the String type to an i32 type. We can do this by using the trim method to remove the newline character from the String type, and then using the parse method to convert the String type to an i32 type.\nuse std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: i32 = guess.trim().parse().expect(\u0026#34;Please type a number!\u0026#34;); println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; println!(\u0026#34;You win! You are the guessing game champion!\u0026#34;), } } If you run the code now, you will see that the code will compile and run.\nHowever, we can still type an alphabet and get away with it. We can fix the input to be only numbers by using the Result type returned by the parse method. The Result is of type enum and can have two values: Ok and Err.\nPoints to remember:\nThe Ok variant of the Result type means that the operation was successful The Err variant of the Result type means that the operation failed. The parse method will return the Ok variant of the Result type if the conversion was successful, and will return the Err variant of the Result type if the conversion failed. We can use the match expression to handle the Result type returned by the parse method. If the parse method returns the Ok variant of the Result type, we will assign the value that is inside the Ok variant to the guess variable. If the parse method returns the Err variant of the Result type, we will print the error message that is inside the Err variant to the console. With these points, we can change the code as follows:\nuse std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: i32 = match guess.trim().parse() { Ok(num) =\u0026gt; num, Err(_) =\u0026gt; { println!(\u0026#34;This is not expected. Please enter an integer\u0026#34;); continue; }, }; println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; println!(\u0026#34;You win! You are the guessing game champion!\u0026#34;), } } If you run the code now, you will see that the code will compile and run. However, if you enter a non-numeric value, the code will not panic. Instead, the code will print the error message that we specified in the Err variant of the Result type. We handled the panic using the Err variant of the Result type.\nLooping until correct number is guessed We can use loop to keep the program running until the correct number is guessed. This can be done as follows:\nuse std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); loop { println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: i32 = match guess.trim().parse() { Ok(num) =\u0026gt; num, Err(_) =\u0026gt; { println!(\u0026#34;This is not expected. Please enter an integer\u0026#34;); continue; }, }; println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; { println!(\u0026#34;You win! You are the guessing game champion!\u0026#34;); break; }, } } } Points to remember:\nWe just use loop keyword to create an infinite loop. We can use break keyword to break out of the loop. We can also use continue keyword to skip the rest of the loop and start the next iteration of the loop.\nRemoving the secret number message We just have to remove the secret number generation part from the code. Once we remove the secret number generation part from the code, we will not be able to print the secret number to the console.\nThe final script should then look like this:\nuse std::io; use rand::Rng; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=101); loop { println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: i32 = match guess.trim().parse() { Ok(num) =\u0026gt; num, Err(_) =\u0026gt; { println!(\u0026#34;This is not expected. Please enter an integer\u0026#34;); continue; }, }; println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; { println!(\u0026#34;You win! You are the guessing game champion!\u0026#34;); break; }, } } } ","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap2/","summary":"Programming a Guessing Game üé≤ In the previous chapter, we learned about the basics of Rust. In this chapter, we will learn about the basics of Rust by building a simple guessing game.\nSetting up the project We will use the Cargo package manager to create a new project called guessing_game. We can create a new project using the following command:\ncargo new guessing_game This creates a new project called guessing_game in the current directory.","title":"Rust Documentation: Chapter 2"},{"content":"What is Rust? Rust is a programming language that is designed to be safe, fast, and concurrent. It is a systems programming language that is used to build low-level software. It is a statically typed language that is compiled to machine code. It is a language that is used to build operating systems, browsers, and other low-level software.\nThis blog post summarizes the key takeaways about the origins of Rust and its usefulness in software development MIT Technology Review: How Rust went from a side project to the world‚Äôs most-loved programming language\nWhy Rust? There are several reasons why one might choose to use Rust as their programming language:\nPerformance: Rust is a systems programming language that is designed to be fast and efficient. Its focus on memory safety and low-level control makes it well-suited for developing high-performance applications.\nMemory safety: Rust\u0026rsquo;s ownership and borrowing model allows for strict compile-time checks that prevent common memory-related bugs such as null pointer dereferences, buffer overflows, and use-after-free errors. This can significantly reduce the occurrence of runtime crashes and security vulnerabilities.\nConcurrency: Rust has built-in support for concurrency and parallelism, making it well-suited for developing scalable and efficient applications.\nCommunity: Rust has a growing and active community that provides a wealth of libraries, tools, and resources for developers. This community is committed to open-source development and creating a safe and inclusive space for programmers.\nCross-platform support: Rust supports a wide range of platforms, including Linux, macOS, Windows, and many embedded systems. This makes it a versatile choice for developing applications that need to run on different platforms.\nOverall, Rust is a modern programming language that offers a unique combination of performance, safety, concurrency, and community support. It\u0026rsquo;s an excellent choice for developing systems-level software, performance-critical applications, and any project that requires both speed and safety.\nWhat is Rust used for? Rust is a systems programming language that is well-suited for developing high-performance, concurrent, and safe applications. Here are some of the common use cases for Rust:\nSystems programming: Rust is often used for developing operating systems, device drivers, file systems, and other low-level software that require direct access to hardware.\nWeb development: Rust is increasingly being used for web development, particularly for building back-end services and APIs. Rust\u0026rsquo;s strong typing, memory safety, and concurrency features make it a good fit for developing fast and reliable web applications.\nGame development: Rust\u0026rsquo;s performance and memory safety features make it well-suited for developing high-performance game engines and libraries.\nNetwork programming: Rust\u0026rsquo;s support for concurrency and asynchronous I/O make it a good choice for developing network services, such as web servers, proxies, and load balancers.\nData processing: Rust\u0026rsquo;s performance and memory safety features make it well-suited for developing data processing and analytics applications, such as data pipelines and machine learning frameworks.\nEmbedded systems: Rust\u0026rsquo;s low-level control, memory safety, and cross-platform support make it a good choice for developing software for embedded systems, such as microcontrollers and IoT devices.\nOverall, Rust\u0026rsquo;s performance, safety, and versatility make it a good choice for developing a wide range of applications, particularly those that require high performance, concurrency, and memory safety.\nInstalling Rust ü¶Ä For Linux based systems, we can install Rust using the following command:\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 https://sh.rustup.rs -sSf | sh This installs the rustup toolchain manager, which installs the latest stable version of Rust by default. The Cargo package manager is also installed by default. Installation for other operating systems can be found here.\nWe can update the rustup toolchain manager using the following command:\nrustup update Hello, World! from ü¶Ä As it is tradition, we will start with the Hello, World! program in Rust.\nBefore starting, we first need to create a new project using the following command:\ncargo new hello_world This creates a new project called hello_world in the current directory. The Cargo package manager is used to manage Rust projects. The Cargo.toml file contains the project metadata and dependencies. The src directory contains the source code for the project.\nmain.rs in src The main.rs file in the src directory contains the source code for the hello_world project. The main function is the entry point for the program. The println! macro is used to print the Hello, World! string to the console.\nfn main() { println!(\u0026#34;Hello, world!\u0026#34;); } Compiling and running the program We can compile the program using the following command:\ncargo build This compiles the program and generates the executable file in the target/debug directory. We can run the program using the following command:\ncargo run This compiles and runs the program. We can also run the program using the following command:\n./target/debug/hello_world Cargo üì¶ Cargo is the Rust package manager and build tool. It is used to manage Rust projects and their dependencies. It is used to build, test, and run Rust programs. It is used to create new Rust projects and add dependencies to existing projects.\nThe Chapter 1 of Rust documentation can be found here.\n","permalink":"https://tanmaychimurkar.github.io/posts/rust/chap1/","summary":"What is Rust? Rust is a programming language that is designed to be safe, fast, and concurrent. It is a systems programming language that is used to build low-level software. It is a statically typed language that is compiled to machine code. It is a language that is used to build operating systems, browsers, and other low-level software.\nThis blog post summarizes the key takeaways about the origins of Rust and its usefulness in software development MIT Technology Review: How Rust went from a side project to the world‚Äôs most-loved programming language","title":"Rust Documentation: Chapter 1"},{"content":"Why Tmux‚ÅâÔ∏è Every software engineer, or people working with software development, have had some sort of interaction with a terminal. Now, terminals are great! If one really masters it, there is no need to use your default OS file explorer to get around files that you need.\nHowever, I personally find it quite chaotic to use many many many terminal windows when trying to work on a single project. The problem of now knowing which terminal window has what can be mind-boggling, and if you have even 5 of such windows, you are already at a trouble to know which terminal has what process running.\nEnter Tmux\nWhat is Tmux‚ùì Tmux is a terminal multiplexer for Ubuntu (and other Linux-based operating systems). It allows users to run multiple terminal sessions within a single terminal window and switch between them easily. Tmux also allows users to detach and reattach sessions, which makes it useful for running long-running commands or keeping a session open even when you are not actively using it.\nIn short, we can split a single terminal into many terminal windows, without having to open many terminal windows for each separate tasks. We can also name our terminal sessions in Tmux, which makes it easier to keep track of which terminal window is for which job. The detach and reattach functions are also super convenient, since we can temporarily suspend our terminals and resume back to them whenever we want.\nSo, let\u0026rsquo;s now see how one would go about using Tmux!!\nInstalling Tmux To install Tmux on Ubuntu, you can use the following command in your terminal:\nsudo apt-get install tmux Once finished, you should have Tmux installed on your machine. Once installed, you can start Tmux by running the command Tmux in the terminal. Once you are in Tmux, you can use various key commands to navigate and manage your sessions, windows, and panes. You can find more information on how to use Tmux by running man Tmux in the terminal. However, I can help you get started with a few useful things to move around tmux.\nTmux shortcuts Create Splits Once you type tmux in your favourite terminal, you should see the terminal on the default directory of your machine. From here, type in your first command using:\n: ctrl + b % When you type the colon :, look at the bottom of the window to see the prompt changing to :. The ctrl + b is the default prefix that Tmux has when you want to execute Tmux commands in a window. The % symbol is used to split the terminal horizontally. Similarly, replacing % with ' will split the window vertically.\nNavigating Panes Now that you have your first split, start typing your commands in any of the splits. To switch between the terminal windows, there are two ways:\nprefix + \u0026lt;direction\u0026gt;: Here prefix is the default prefix Ctrl + b and direction is one of the arrow keys (up, down, left, or right) to move the focus to the corresponding pane. prefix + o: To move the focus to the next pane in the current window. prefix + { or prefix + } : To move the focus to the next or previous pane in the current window prefix + q + \u0026lt;pane-number\u0026gt;: Prompts the number of the panes on screen, and you choose the number where you want to switch. Resize Windows We can also resize our splits that we created with the following commands:\nprefix + \u0026lt;direction\u0026gt; + \u0026lt;arrow key\u0026gt;: to resize the current pane in the specified direction. prefix + \u0026lt;direction\u0026gt; + \u0026lt;arrow key\u0026gt; + \u0026lt;Shift\u0026gt;: to resize the current pane more quickly in the specified direction. Tmux configuration file The default prefix that Tmux provides is a bit unnatural to many programmers, and this can be fixed very easily. To fix this, you just need to create a tmux.conf file in the root system, and add the following line there:\nset-hook -g after-new-session \u0026#34;source-file ~/.tmux.conf\u0026#34; unbind-key C-b set-option -g prefix C-\u0026lt;enter new prefix key here\u0026gt; bind-key C-g send-prefix Once you enter your favourite prefix key in the set-option command, you will have changed your prefix. For the changes to appear, either restart tmux server, or type the following in any of the tmux panes:\n: source ~/.tmux.conf This will source your changes from the config file, and your prefix should be changed.\nSome popular changes to replace default behaviour in Tmux Generally, these are the configuration files that I have seen programmers use quite often:\nset-hook -g after-new-session \u0026#34;source-file ~/.tmux.conf\u0026#34; unbind-key C-b set-option -g prefix C-g bind-key C-g send-prefix set-window-option -g mode-keys vi bind e setw synchronize-panes on\\; display-message \u0026#34;Panes are synchronized\u0026#34; bind E setw synchronize-panes off\\; display-message \u0026#34;Panes not synchronized\u0026#34; bind h select-pane -L bind j select-pane -D bind k select-pane -U bind l select-pane -R To know what each of them do, type the prefix key that you set, and then the alphabet following the bind keyword in the above configuration.\nThis can be used as a good starting point for your tmux.conf file.\nCongratulations You are now a pro terminal user who uses tmux to set up their workflow. Hopefully, you should soon see a boost in your productivity, and will also fall in love with your terminal :)\nUntil next time!!\n","permalink":"https://tanmaychimurkar.github.io/posts/tools/tmux/","summary":"Why Tmux‚ÅâÔ∏è Every software engineer, or people working with software development, have had some sort of interaction with a terminal. Now, terminals are great! If one really masters it, there is no need to use your default OS file explorer to get around files that you need.\nHowever, I personally find it quite chaotic to use many many many terminal windows when trying to work on a single project. The problem of now knowing which terminal window has what can be mind-boggling, and if you have even 5 of such windows, you are already at a trouble to know which terminal has what process running.","title":"Tmux-Ease your terminal workflow"},{"content":"Why Docker Compose‚ÅâÔ∏è In the previous post, we saw how to run a Docker Container from a Docker image, either custom or pre-built image from the DockerHub. However, as we discussed, a big software is not built on just one Docker Container but many containers, working as microservices. When running multiple such containers, it is important that they are able to interact with each other, be able to exchange data, and thus act as independent blocks of a larger piece of software. In this post, we will go over how to thus run multiple containers together.\nWhat is Docker Compose file?üêô Running multiple containers can be done by a Docker Compose file, that acts as a configuration file to choose multiple Docker Images and start them as containers, such that they are able to interact with each other.\nDocker Compose file, also known as docker-compose.yml, is a configuration file used to define the services, networks and volumes for a multi-container Docker application. With the help of docker-compose command, the services defined in the file can be easily started, stopped, scaled, and managed as a single unit. The file is written in YAML format, which is easy to read and understand. It allows developers to define the complete environment for an application in a single file, and manage it more efficiently.\nDon\u0026rsquo;t be fooled by me throwing the terms services, networks and volumes from the description as some sort of concepts that everyone must know. These are terminologies specific to the docker-compose.yml file, and are used as a standard base to create the compose configuration file. Let\u0026rsquo;s look at them in a short detail below.\ndocker-compose.yml terminologyüìö Below is a list of some of the main terminology that a docker-compose.yml file should follow.\nservices: The services section is used to define the individual components or microservices that make up the application. Each service is defined as a separate block, with its own configuration options. The options available for each service include the image to use, environment variables, ports to expose, volumes to mount, and links to other services. For example, a simple web application might have two services: a web server and a database. The web server service would be defined with the image to use, environment variables, and ports to expose. The database service would be defined with the image to use, environment variables, and volumes to mount.\nnetworks: The networks section is used to define virtual networks that the services in the application can connect to. Services can be connected to multiple networks, allowing them to communicate with each other. When a service is connected to a network, it is given an IP address on that network and can communicate with other services on the same network using their IP addresses. This allows services to be isolated from the host system and from the external network, while still being able to communicate with each other. It\u0026rsquo;s also possible to create custom networks and connect services to them. For example, a docker-compose.yml file may define a default network called default and a custom network called backend where all services that need to communicate with each other privately are connected to.\nvolumes: The volumes section is used to define storage volumes that can be used by the services in the application. A volume is a way to store data outside a container\u0026rsquo;s filesystem, so that it can be accessed by multiple containers and persist data even if the container is deleted. The storage volumes defined by us are stored in our local machine, under the /var/lib/docker/volumes folder. Volumes can be defined in a docker-compose.yml file and then mounted to a specific service\u0026rsquo;s container. They can also be defined as external, which means that they are managed outside docker-compose and can be shared by multiple applications. For example, if you have a service that needs to store some data, you can create a volume and mount it to that service\u0026rsquo;s container. This way, even if the container is recreated or deleted, the data stored in the volume will persist. It\u0026rsquo;s also possible to use named volumes, which allows you to reference the volume by name instead of by path on the host. This can make it easier to manage volumes across different environments.\nThese are only some of the standard terms that are in the docker-compose file. However, let us now look at an example of the docker-compose file itself to see what the structure of it is.\nStructure of the docker-compose.yml fileüìã As we read before, the docker-compose.yml is only a YAML configuration file. Below is the structure of a very small compose file, that runs the PostgreSQL and the pgAdmin UI tool together.\nThe below docker-compose.yml file is designed in such a way that we use most of the possible terms that appear in the docker-compose.yml file. Do not worry if you don\u0026rsquo;t completely understand each and every term in the file, we will go through their descriptions later. For now, let us have a look at how the file itself looks first.\nNOTE: If you want to learn more about what YAML files are, have a look at YAML or read the official YAML documentation.\nversion: \u0026#34;3\u0026#34; services: postgres: image: postgres restart: always environment: POSTGRES_PASSWORD: postgres POSTGRES_USER: postgres ports: - 5432:5432 volumes: - postgres:/var/lib/postgresql/data pgadmin: image: dpage/pgadmin4 environment: PGADMIN_DEFAULT_EMAIL: admin@pgadmin.com PGADMIN_DEFAULT_PASSWORD: password PGADMIN_LISTEN_PORT: 80 ports: - 1542:80 volumes: - pgadmin:/var/lib/pgadmin depends_on: - postgres volumes: postgres: pgadmin: We can now see that the terms services and volumes are defined in the above compose file, however there are also new terms that we did not yet see. Let us now go through the compose file above to see what each entry means.\npostgres/pgadmin: This is the name we want to give to the services before we start defining them. Once we run the containers defined in the compose file, we will see each running container for a service by this name. And just like in the previous post, we can exec into each of the services by the name that we choose to give it. Please note that the name is given by us, and is not something that is attached to a particular image. image: This is the image that we want the service to use when we run it. This can be either an image from the DockerHub, or our own image. If we are using owr own custom image in the compose file, then it\u0026rsquo;s relative path compared to the docker-compose.yml file should be passed in the image term. environment: This term defines a list of environment variables that we want our services to use. The environment variables are not shared across different services, and should be defined individually for each of the service that we define in the docker-compose file. ports: This term is central for the end user running the docker-compose file. This term defines the port that is to be exposed on the local machine from inside the docker network that is defined when the docker-compose.yml file is run. For us to be able to access a running application, we define the port in the first part of the ports, and the second part is the port that the service is running on inside the docker network. volumes: There are 2 ways volumes can be defined in the docker-compose file: named volumes: These volumes are managed by docker-compose and can be referenced by name in the docker-compose.yml file. bind mounts: These volumes are defined by a specific path on the host machine and mounted inside the container. Usually, it is advised to use named volumes instead of bind volumes in the compose file, as named volumes are managed directly by Docker, and can be moved/deleted using the Docker CLI. The volume that is defined in the above compose file are also named volumes, where the first half of the volumes term is the name we want to give to the names volume, and the second half is the actual location of the directory that we want to be stored in our named volume. depends_on: This is a term that controls if a service is dependent on any other service. We have to define the names of the services that we want to start before the current service where the depends_on term is defined. This makes sense by looking at the above scenario: We do not want the pgadmin service to start before the postgres service, as there will be no database to attach to, and thus the tool will not be able to locate our database. Phew!! That was a very long terminology that is followed inside the docker-compose.yml file. However, there should still be some alarm bells ringing in your head if you read the above descriptions.\nHow do we know what volume to mount on our local machine? How do we know what environment variables to define for a service to be able to run successfully? What is the default port that are particular service starts at when we run it? Fret not! These questions all have a answer that is easy to find.\nGet variables for a service based on the imageüîç All the above questions are dependent on the Docker Image that a particular service is using. For example, if you look at the Environment Variables section of the postgres image on DockerHub, then you will find that the environment variable POSTGRES_PASSWORD is the only required variable for the container to run successfully. We also pass the POSTGRES_USER variable just so we see how to pass other environment variables to a particular service as well.\nAnd from the PG_DATA section on the webpage, we can find that default directory where postgres stores the data is /var/lib/postgresql/data directory, and that is the directory that we choose to mount in a named volume in our compose file.\nNow that we have MOST of the terminology that a docker-compose.yml file has, it is time to run the compose file to see things in action.\nIMPORTANT: Before running the next part, be sure to have Docker Compose installed. Please follow this link to install the Compose tool on your machine.\nRunning your containersüì¶ Run the below command in your terminal to start all the services from the docker-compose.yml file.\ndocker-compose up NOTE: Depending on which tool you install, you should either have the docker-compose up command or the docker compose up command.\nOnce you run the command, you should see something like this in your terminal window:\n\u0026gt; docker-compose up \u0026gt; docker-compose up Creating network \u0026#34;user_default\u0026#34; with the default driver Pulling postgres (postgres:)... latest: Pulling from library/postgres 8740c948ffd4: Pull complete c8dbd2beab50: Pull complete 05d9dc9d0fbd: Pull complete ddd89d5ec714: Pull complete f98bb9f03867: Pull complete 0554611e703f: Pull complete 64e0a8694477: Pull complete 8b868a753f47: Pull complete 12ed9aefbab3: Pull complete 825b08d51ffd: Pull complete 8f272b487267: Pull complete ba2eed7bd2cc: Pull complete ff59f63f47d6: Pull complete Digest: sha256:6b07fc4fbcf551ea4546093e90cecefc9dc60d7ea8c56a4ace704940b6d6b7a3 Status: Downloaded newer image for postgres:latest Pulling pgadmin (dpage/pgadmin4:)... latest: Pulling from dpage/pgadmin4 8921db27df28: Pull complete d10ee54273de: Pull complete 3cf1e77a6858: Pull complete 07b97201e1e9: Pull complete b77bae207213: Pull complete 0fcc0c06a94f: Pull complete 3c9a847b1b09: Pull complete 6ad9bb3cc48b: Pull complete 246134c219b2: Pull complete ac0085153d3a: Pull complete 8860f79c6eae: Pull complete 8b0e5eb7caab: Pull complete 2387bc6168f4: Pull complete 0be474dc7144: Pull complete Digest: sha256:79b2d8da14e537129c28469035524a9be7cfe9107764cc96781a166c8374da1f Status: Downloaded newer image for postgres:latest Status: Downloaded newer image for dpage/pgadmin4:latest Creating user_postgres_1 ... done # Creating Users Creating user_pgadmin_1 ... done Attaching to user_postgres_1, user_pgadmin_1 # Starting services postgres_1 | postgres_1 | PostgreSQL Database directory appears to contain a database; Skipping initialization postgres_1 | postgres_1 | 2023-01-21 23:47:11.847 UTC [1] LOG: starting PostgreSQL 15.1 (Debian 15.1-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit postgres_1 | 2023-01-21 23:47:11.847 UTC [1] LOG: listening on IPv4 address \u0026#34;0.0.0.0\u0026#34;, port 5432 postgres_1 | 2023-01-21 23:47:11.847 UTC [1] LOG: listening on IPv6 address \u0026#34;::\u0026#34;, port 5432 postgres_1 | 2023-01-21 23:47:12.035 UTC [1] LOG: listening on Unix socket \u0026#34;/var/run/postgresql/.s.PGSQL.5432\u0026#34; postgres_1 | 2023-01-21 23:47:12.233 UTC [29] LOG: database system was interrupted; last known up at 2023-01-17 13:43:30 UTC postgres_1 | 2023-01-21 23:47:14.213 UTC [29] LOG: database system was not properly shut down; automatic recovery in progress postgres_1 | 2023-01-21 23:47:14.315 UTC [29] LOG: redo starts at 0/249F8F8 postgres_1 | 2023-01-21 23:47:14.315 UTC [29] LOG: invalid record length at 0/249F9E0: wanted 24, got 0 postgres_1 | 2023-01-21 23:47:14.315 UTC [29] LOG: redo done at 0/249F9A8 system usage: CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s postgres_1 | 2023-01-21 23:47:14.469 UTC [27] LOG: checkpoint starting: end-of-recovery immediate wait postgres_1 | 2023-01-21 23:47:14.948 UTC [27] LOG: checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.149 s, sync=0.049 s, total=0.564 s; sync files=2, longest=0.025 s, average=0.025 s; distance=0 kB, estimate=0 kB postgres_1 | 2023-01-21 23:47:14.999 UTC [1] LOG: database system is ready to accept connections # Now pgAdmin starts pgadmin_1 | [2023-01-21 23:47:19 +0000] [1] [INFO] Starting gunicorn 20.1.0 pgadmin_1 | [2023-01-21 23:47:19 +0000] [1] [INFO] Listening at: http://[::]:80 (1) pgadmin_1 | [2023-01-21 23:47:19 +0000] [1] [INFO] Using worker: gthread pgadmin_1 | [2023-01-21 23:47:19 +0000] [86] [INFO] Booting worker with pid: 86 From the above output of running the docker-compose.yml file, we see note the following:\nThe images are first pulled, which is what we saw in the Docker Images post, Once they are pulled, we see the there are users created that we had defined in the compose file above. However, you should see at # Creating Users line in the description above to see that the user names have the prefix _1 attached to them. This is the default behaviour by Docker, and we can have our own prefix by passing the argument -p OUR_PREFIX_NAME. On the comment # Starting Services in the above output, we see that the services themselves have started. We see first logs from the postgres service, and then from the pgadmin service. Notice that the pgadmin service only starts after the # Now pgAdmin starts comment in the above output. This is inline with the depends_on clause that we had defined in our compose file. Once you see the above output, you can go on localhost:1542 (or whichever port you had chosen to be exposed on your local machine), and you should see the pgAdmin default webpage. Once there, login with the email and the password defined in the PGADMIN_DEFAULT_EMAIL and the PGADMIN_DEFAULT_PASSWORD environment variables. You should then be logged in, and should then see that the default postgres database is also visible.\nCongratulationsüôåüéâü•≥üôåüéâü•≥ Well Well Well!! Congratulations to you on being a pro Docker user and on coming this far.\nYou are now equipped with the most awesome and popular microservice creation tool in your skills bag. With this skill, you are now unstoppable in creating the largest piece of software by dividing it into many smaller parts, that are much easier to manage than a giant Monolith of code.\nThank you for reading this far, and I hope I was able to help you learn something new!! Until next time üòéüòéüòé\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_compose/","summary":"Why Docker Compose‚ÅâÔ∏è In the previous post, we saw how to run a Docker Container from a Docker image, either custom or pre-built image from the DockerHub. However, as we discussed, a big software is not built on just one Docker Container but many containers, working as microservices. When running multiple such containers, it is important that they are able to interact with each other, be able to exchange data, and thus act as independent blocks of a larger piece of software.","title":"Docker Compose"},{"content":"What is a Docker Container?üì¶ In the previous post, we saw how to find Docker images form the DockerHub, and also how to create our own Docker image that executes a function. In this post, we will go more over the execution part of Docker, mainly about how to run a Docker image as a container.\nDocker Containers are Docker images that become containers at run time. Docker containers are short pieces of software that runs an application quickly, as a lightweight standalone package. The containers need an engine to run, and this is the Docker Engine.\nBasically, Docker containers make it easier to decentralize a large piece of software such that it can run in isolated environments, and they are what we can refer to as microservices. So in this part of the post, we will be running our first use case of microservices. We will start with running a single Docker image first, then we will combine many Docker images to run together so that they can interact with each other and run the whole software.\nRunning a ContainerüèÉ In the previous post, we saw how we can either pull a pre-built Docker image from the DockerHub, or create our own custom image. We saw at the end that we had to run a specific command in the terminal to get the output from a Docker image. The commands that we ran in the previous post ran the Docker image, and during runtime, it created a Docker container that runs the piece of code that we put inside our own image or the outputs from a pre-built image from the DockerHub.\nIf you followed along with the previous post, you should now see the Ubuntu image in the terminal when you execute the below command in your terminal.\n\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE custom_image latest 432ba341135f 4 weeks ago 932MB ubuntu latest 6b7dfa7e8fdb 5 weeks ago 77.8MB In case you did not follow the previous post, we can run the following command in the terminal first to pull a Docker image and then continue:\ndocker pull ubuntu:latest Now we are ready to proceed. To start the Docker container, we can start by typing the following command in the terminal\ndocker run ubuntu If all is correct, you should see, well nothing. But why is that? We just ran our Ubuntu image as a Docker container, but we don\u0026rsquo;t see anything on the terminal when we run it.\ndocker ps command To check whether a particular image is successfully run or not, we need to execute the following command in the terminal:\ndocker ps The docker ps command lists all the containers. So if you ran the Ubuntu image as per the previous step, then the docker ps command should show that the Ubuntu container is running. Let\u0026rsquo;s try to check if that is the case. In the terminal, execute the following command:\ndocker ps However, the output we see in the terminal should be the following:\n\u0026gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Hmm, weird right? The documentation says that the docker ps command gives us a list of the containers. But we do not see anything in the terminal. This is because the docker ps command only list the containers that are running by default. And for our Ubuntu image, we did not give any specific command to run when we started the container via the docker run command. Which is why it is not showing up under the docker ps command. To check if the container was ranning when we started it, we need to pass the -a flag to the docker ps command. Let\u0026rsquo;s run the following command in the terminal to check this:\n\u0026gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4c42acd7b1cd ubuntu \u0026#34;bash\u0026#34; 10 minutes ago Exited (0) 10 minutes ago condescending_villani We should see something like above in the terminal, with a different string under the NAMES and the CONTAINER ID column. Let\u0026rsquo;s see what terms shown in the output of the docker ps -a command mean.\nBelow is a list explaining what each of the terms given in the output above mean:\nCONTAINER ID: This column lists the id that a Docker container is given when it is run. This is a random id that is generated everytime a Docker container is run. If we run the same Docker image multiple times to start containers, it is very unlikely that the CONTAINER ID will be the same across different containers. IMAGE: This column gives the name of the Docker image that was used to start the Docker container. In our case, since we started the container using the command docker run ubuntu in the terminal, the IMAGE section correctly lists the ubuntu image in its run. COMMAND: This column lists the default command that is run when the Docker container is started. Since for the case of the ubuntu container, we did not specify any command, a default bash command is run on startup. CREATED: This field mentions the time when the container is started. STATUS: This field gives us a status of the container. In our case, we see the status code as being Exited (0) 10. This signifies that the ubuntu container was started, and is now shut down and is not running. The STATUS field helps us figure out the current status of a Docker container once it is started, and it can take different values, ranging from Creating ... to Up ..., which indicates that the container is either starting up or it is running for the amount of time mentioned after the Up string, respectively. PORTS: This field gives a list of ports that are to be exposed from inside the Docker container to the local user\u0026rsquo;s machine, so that the local user can access the port outside of Docker\u0026rsquo;s network NAMES: This field outputs the name that the docker container has when it is running. The name of a Docker container when it is run is also generated at random everytime a Docker container is started, but unlike the CONTAINER ID field, the name can be controlled and kept static for a particular Docker container. So, these are all the fields that are showed by the docker ps -a command. Now let\u0026rsquo;s start tampering with the docker run command to get a bit more out of the containers when we run them.\nPassing arguments to docker run command‚ÄºÔ∏è In the previous step, we just used the docker run command out of the box on the Ubuntu image. However, that did not give us much, not even a friendly terminal to let us inside the container that is running. Let\u0026rsquo;s now try to get inside the Ubuntu container to check what it has.\nTo do this, we first need to make the Ubuntu container execute a different command at runtime when it is started. For this, we can pass additional arguments to the docker run command in the terminal as follows:\ndocker run ubuntu sleep 3600 The sleep command that we pass is not a Docker argument, but a Linux system argument.\nTip: You can check more about the sleep command by running man sleep in your terminal (Only works for Linux-based OS like Ubuntu or MacOS)\nThe sleep command will override the default bash command from the Ubuntu container, and make the container sleep for the 3600 seconds 60 minutes. That should give us enough time to check what is inside the container.\nSo, once we have run the above command, we should see that the terminal does not exit like in the initial docker run command, but is in a way just stuck. However, if you open a new terminal and list all the containers with docker ps -a, we should now see the following:\n\u0026gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8ec5ceccbd72 ubuntu \u0026#34;sleep 3600\u0026#34; 3 seconds ago Up 1 second fervent_mclaren Notice how in the STATUS field it now shows Up 1 second. And also take a look COMMAND section to see that it now shows sleep 3600 as the command instead of bash like the previous case. That means the command that we passed while starting the container worked, and is executed as soon as the Ubuntu container is started. Let us now see what is inside the Ubuntu container.\nGoing inside a running container Now that the ubuntu container is running, we can look inside it. The default method to look what is inside a container is to get a terminal, and we can do the same for the ubuntu container. To get a terminal inside the container, we can run the following command:\n\u0026gt; docker exec -it \u0026lt;identifier\u0026gt; The exec command is used to run a command inside a running container. And to let Docker know which container we want to choose to execute the command, we need to pass an \u0026lt;identifier\u0026gt; above, which can either be the NAME of the container or the CONTAINER ID. Let\u0026rsquo;s pass the CONTAINER ID for now, but we can pass NAME in exactly the same way.\nPro Tip: For passing the CONTAINER ID as an identifier for the exec command, we do not need to pass the full container id. Instead, we can just pass the first 3 characters of the CONTAINER ID to the exec command, and it will still be executed inside the correct running container.\nTo execute and get a shell inside the running container, run the following command:\ndocker exec -it 8ec bash Please make sure to pass the correct first 3 characters from your CONTAINER ID, since every CONTAINER ID is randomly generated, and your CONTAINER ID will not be the same as mine.\nOnce we run the above command in a new terminal, we should see the following output:\n\u0026gt; docker exec -it 8ec bash root@8ec5ceccbd72:/# Well, well. We are now inside our running Docker container!!!üêï\nWe can now ls to check what files/directories the container has, and we can look around inside them as part of exploration. Let\u0026rsquo;s now see how we can give a name to a Docker container when we run it, and why is it useful.\nSome tips for running Docker containersüí° It is very beneficial to give your Docker container a name, since doing so will always maintain a streamlined process of seeing inside the container and accessing it for checking your processes. This can be done by passing in the --name flag to the docker run command, which is a Docker flag unlike the sleep command we saw earlier. Let\u0026rsquo;s execute the following command in the terminal: docker run --name my_ubuntu_image ubuntu sleep 1000 You can pass either my_ubutu_image as the name of your container, or you can get creative and pass something that you like as a name for your Docker container. Once we run the above command, you can open a new terminal and check running containers with docker ps -a. Once you do, you should now see something like the following output:\n\u0026gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f04164a6395f ubuntu \u0026#34;sleep 1000\u0026#34; 3 seconds ago Up 1 second my_ubuntu_image Notice how the docker container now has in the NAMES field the name my_ubuntu_image, or whatever name you passed along in the --name flag. Now if you want to exec inside the running container, instead of passing the CONTAINER ID, we can pass the name of the container and it will go inside. Let\u0026rsquo;s try this out with docker exec -it my_ubuntu_image bash to get bash inside the docker container. You should definitely see something like the following:\n\u0026gt; docker exec -it my_ubuntu_image bash root@f04164a6395f:/# Now we can always refer to our container while running commands with its name.\nNow that we have a Ubuntu container running, we need to know how to stop it. We need to stop old containers before running new ones, since Docker does not let us run two containers with the same name twice. To check this, run the following command again in a new terminal: docker run --name my_ubuntu_image ubuntu sleep 1000 You should get the following error message:\n\u0026gt; docker run --name my_ubuntu_image ubuntu docker: Error response from daemon: Conflict. The container name \u0026#34;/my_ubuntu_image\u0026#34; is already in use by container \u0026#34;f04164a6395f2c472bc5c6f6e59e304baa793b5d7edf106066e0764b51e1ad5d\u0026#34;. You have to remove (or rename) that container to be able to reuse that name. The error message tells us that there is a conflict with the container name, since we are already running a Ubuntu container with the same name. To rerun a new container with the same name, we first need to stop the one that is running currently. For this, we need to run the following command in a new terminal:\n\u0026gt; docker stop my_ubuntu_image Once you run this command, the terminal will be back after the command is executed successfully, and if you now get a list of all the containers, you should see the following:\n\u0026gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f04164a6395f ubuntu \u0026#34;sleep 1000\u0026#34; 12 minutes ago Exited (137) 9 seconds ago my_ubuntu_image As you can see, the STATUS field now shows Exited ... under it instead of the previously shown Up for x seconds. This means that our Ubuntu container has stopped running, and we are ready to start another container with the same desired name.\nAs per the above step, you now know how to stop a docker container. However, if you run the container again, you will still get the same error message with the name conflict as before. That is because docker not only needs you to stop the container, but to completely remove it before starting a new container. To do this, we can run the following command in a new terminal: docker system prune You should then show the following prompt in your terminal window:\n\u0026gt; docker system prune WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all dangling images - all dangling build cache Are you sure you want to continue? [y/N] docker system prune simply removes all the unnecessary data from your Docker environment, like stopped containers, containers that could not start correctly, or cache that a container created on your machine when it was started. In the above prompt, type y and press enter to let docker clear all stopped containers and the data related to them. Once this is successful, you should see a message as follows:\nDeleted Containers: f04164a6395f2c472bc5c6f6e59e304baa793b5d7edf106066e0764b51e1ad5d Total reclaimed space: 98B This message indicates that all the stopped containers are now removed, alongwith the caches that they had created when started. To check if there are any containers still, you can run docker ps -a.\nIf you want to manually remove only one specific container from the stopped containers afters stopping it, you can run the following command instead:\ndocker rm \u0026lt;container name or id\u0026gt; This will remove only the container whose name or id you passed.\nThe methodology of running containers from pre-built docker images can be extended to running custom images as containers that we create according to the previous post, or any custom container of your choice. All the list of commands remain the same, only the pre-built ubuntu image from the above commands needs to be replaced with your own custom image.\nRunning multiple containers and make them interact with each other So far, we have seen how to run a single image as a container, give it a name, pass some commands to override the default commands, how to stop and remove it. However, large pieces of software are rarely built on only one running container, and there are always many containers handling one specific task of the software independent of other tasks that are run by the software.\nFor this, we need to run multiple containers at once, and these containers also need to be able to interact with each other in order to make the software run successfully. Once simple examples where different containers can be run to do different tasks is run a PostgreSQL database to store some results from an API, a container to run the API itself, and a pgAdmin UI tool to interact with the database to check if the data that the API returns are being stored successfully inside the postgreSQL database. This sounds like a very general purpose use-case that many companies have in common, and this can be managed very efficiently via docker containers. We will see more about this in the next post of Docker Compose files, which allows us to run multiple containers at once.\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_containers/","summary":"What is a Docker Container?üì¶ In the previous post, we saw how to find Docker images form the DockerHub, and also how to create our own Docker image that executes a function. In this post, we will go more over the execution part of Docker, mainly about how to run a Docker image as a container.\nDocker Containers are Docker images that become containers at run time. Docker containers are short pieces of software that runs an application quickly, as a lightweight standalone package.","title":"Docker Containers"}]