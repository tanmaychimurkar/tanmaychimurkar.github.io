[{"content":"Why and What‚ÅâÔ∏è Ô∏èIn Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.\nThis is the very scenario where things can fall apart very easily!\nWhy Dockerü§î In scenarios like mentioned above, wouldn\u0026rsquo;t it be useful to have a tool that makes sure that a software is bundled in a way that is irrespective of the base dependencies it requires to be built on?\nAs I primarily work in Pythonüêç, I would like to throw in an analogy. This abstraction tool can be thought of like a virual environment, with each project having its own separate dependencies which do not interfere with a different project\u0026rsquo;s virtual environment, and every environment satisfying all the module level dependencies that the project needs.\nIn short, the tool that we need should have isolation and dependency matched as per the part of the project that is running on it!\nHaving such a tool to manage whole software, such that it handles all the base dependencies like that of the OS and any other package level dependencies are managed for us would be great, wouldn\u0026rsquo;t it?\nWhat is Dockerüê≥ In-line with the objectives that we want the above-mentioned tool to perform, let\u0026rsquo;s take a look at Docker.\nDocker helps abstract away the dependencies for components between varying OS, software, and hardware requirements, and lets every part of the project run in an isolated environment.\nFeels like technical mumbo jumbo? Well let\u0026rsquo;s take another go at understanding this. The abstraction that Docker provides can be thought of in the following way:\nImagine breaking the whole software into multiple smaller pieces, with each piece handling one part of some logic. This is what we call an isolated part of the project. Each part will naturally have a set of requirements in the forms of packages or configurations for it to be able to run correctly. This is the dependency that the project has. Running our project using Docker will abstract away the above said requirements for other people, and anybody running our project will use the configurations we have set when moving the project to Docker. I hope it is more or less clear what Docker does. If not, fret not! Things should become clearer as we go further with terminology.\nTerminologyüìñ So far, we have been trying to understand what Docker does in our own analogy and terms. However, things can go out of hand if one does not follow a standard terminologyüê±.\nLet\u0026rsquo;s dive in the terminology that will make our life easier to follow.\nObviously, one should at the end refer to the official glossary mentioned by Docker. However, to quickly get us started, I have mentioned some base terminologies below.\nDocker Image‚úíÔ∏è Since we need to create an isolated environment, we first need to decide what will the base of such an environment have. This base that each isolated environment needs is defined in a Docker image, which contains union of layered filesystems stacked on top of each other.\nWe can think of image as a small pre-compiled software on which we can run our assigned part of the project, and using an image is like installing Python or Ubuntu on your own machine.\nBecause of the awesome strength of the Docker community, they decided to keep a collection of the images that people need. This collection of images is listed on the Docker Hub, and we can find all sorts of images, like Alpine Linux and Python.\nNote: Although the Docker hub has many images readily available, we can also create our own Docker images. And as we read above that images are union of layered filesystems, our own image will also be a layer over some base image.\nA more detailed explanation of Docker Images is here.\nDocker Containerüì¶ So we saw that image in Docker is a base system that we want to run our piece of the project. When we run such an image, we get a Docker container.\nIn short, a Docker container is a running instance of a Docker image.\nA container always needs an image, and along with it, we sometimes pass a set of execution parameters such that the container has the parameters that we want, for example it\u0026rsquo;s name.\nA more detailed explanation of Docker containers is here.\nSumming it up!üí° What we saw so far is a very basic understanding of what Docker is, why we might need it, and what are the basic things we need to understand for breaking our project into small running containers. These small running containers can also be thought of as very small virtual machines, and this will be more clear when we look at the Docker Containers post. In the next part, let\u0026rsquo;s look at Docker Images in a bit more detail and how we can create our image. üò∫\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_intro/","summary":"Why and What‚ÅâÔ∏è Ô∏èIn Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.","title":"The basics of Docker to get started"},{"content":"Docker Imagesüê≥ As we saw in the basics of Docker post, the base flow of every Docker container is an image. A Docker image, whether custom or pre-built, is absolutely necessary for us to be able to run anything using Docker.\nIn essence, a Docker image is a union of layered filesystem stacked on top of each other. This stands true fro pre-built images as well as custom images that we might create using some pre-built image as a base.\nTriviaüí°: If every Docker image is a set of layered instructions, then how is the first Docker image created? What did the very first Docker image have as a layer to be built on top of?\nHoping that the description of the Docker images is clear now, let\u0026rsquo;s now take a look at our first Docker image. And what better to look at than the image of Ubuntu itself!?!?\nDocker Image on Hub Use this link to navigate to the Docker Hub page of the Ubuntu image. Once there, go through the \u0026lsquo;What is Ubuntu?\u0026rsquo;, and \u0026lsquo;What\u0026rsquo;s in this image?\u0026rsquo; section. As you might have read, this image is Ubuntu. We can use this image for general purpose stuff on Ubuntu.\nNow let\u0026rsquo;s go to the \u0026lsquo;Tags\u0026rsquo; section on the webpage, and see what we find there. We can see that there many tags, and the first one that appears should have the TAG \u0026lsquo;Latest\u0026rsquo;, and on it\u0026rsquo;s right, there should be a command that says: docker pull ubuntu:latest. If we look at the next tag after Latest, notice how the docker pull command changes slightly with the name of the TAG that we are referring to! Also, take a look at the size of the image. It should be around 25-30 MB. WHATTTTTTT!!!! This means that the docker image that can run Ubuntu instructions is only 30 MB in size.üôÄ\nLet\u0026rsquo;s stop for a moment here and summarize what we have seen so far:\nDocker Hub has many pre-built images ready for us to explore Almost all the images have a description about what they are and a small summary of what they contain. Some have much greater description in terms of the Environment Variables, but let\u0026rsquo;s look at it later All the pre-built images on Docker Hub have Tags, and every tag is a version of the image Every image tag has a set of instructions about how to pull it. Let\u0026rsquo;s understand what the pull command does!üêï\nDocker Pullüßó Seeing that we have a command linked to a image on Docker Hub, naturally the next step is to get our hands dirty. This helps me get out of my comfort zone, but also helps me bring a concept that I am trying to grasp much easier to understand. I hope this also works the same for youüêà\nImp. Noteüê≥: For getting our hands dirty here, it is advised to go through the installation of Docker Desktop. Personally, I like the Docker Engine with the compose tool more, but to begin with, either of the two installations should work fine.\nWith Docker installed on your system, let\u0026rsquo;s verify the docker version. This can be done by opening a terminal and typing:\ndocker --version If you see a message with version, then we are good to get into the fun part.\nIn the terminal, type the below command to check the current images that docker has on your machine:\ndocker images If you see nothing, or only see the hello-world image, then we are good to go. Let\u0026rsquo;s now run the command that we saw on Docker Hub page of Ubuntu:\ndocker pull ubuntu:latest Once you run this command, you should see something similar to this:\nlatest: Pulling from library/ubuntu 6e3729cf69e0: Pull complete Digest: sha256:27cb6e6ccef575a4698b66f5de06c7ecd61589132d5a91d098f7f3f9285415a9 Status: Downloaded newer image for ubuntu:latest docker.io/library/ubuntu:latest What docker pull does is it pulls the image from Docker Hub into your local machine. Once the above output is visible in the terminal, we can check the images again with docker images, and now we should see the ubuntu image with the latest tag in the terminal.\nThis is the way for us to pull pre-built images from Docker Hub\nDockerFileüê≥ Since Docker images are a union of layered filesystem stacked on top of each other, we can also build our own custom image that does something that we want by building it on top of another pre-built image. To build our own image, we first need to create a DockerFile, which is a configuration file that has commands that Docker uses to build our image. Let\u0026rsquo;s have a look at the terminology that the DockerFile has.\nTerminologyüìñ DockerFile is just a text document that contains a set of instructions in order that Docker has to execute to build our image. Let\u0026rsquo;s now look at some of the most used commands that we need to build our own Docker image, while the main list of commands is still available under DockerFile reference.\nFROM: This commands sets the base image that we want our own image to be built on top of. Every DockerFile should start with a FROM command, since every image is built on top of another image.\nRUN: As the name suggests, this command is used to execute a set of instructions on top of the base image that we use for our own custom image. RUN commands can be run in two ways: either in shell form, or in exec form, which means there are two ways to run commands for the RUN instruction. The shell form for RUN directly uses the instruction like RUN sh -c echo hello, while in the exec form, the same command would be run as RUN [\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;echo hello\u0026quot;]\nCOPY: This command is used to copy something from our project code inside the Docker image. The copy command needs a source location to copy from and a destination location to copy inside the Docker image.\nWORKDIR: Sets the current working directory for the Docker image, such that all the instructions that follow the after setting WORKDIR will be executed from that directory.\nCMD: This instruction is used to specify the default arguments that we want the Docker image to take when we run it. There can only be one CMD instruction in a DockerFile, and if we have multiple, then only the last one will be executed. CMD instruction works as setting default arguments when we want to run an image.\nENTRYPOINT: As CMD sets a default command, the ENTRYPOINT command can override it. However, how the command is overridden depends on the whether the shell form is used or the exec form is used. The most intuitive explanation of the interaction between CMD and ENTRYPOINT is in the Docker documentation\nWhew!!üòå That was a lot of terminology, and we have not even covered eveything from the DockerFile reference. However, we do not need to understand how each and every parameter works in order to get started. Instead, these are the most common commands that are usually inside a DockerFile while building custom images.\nLet\u0026rsquo;s now build our own Docker image by building a DockerFileü§©\nCreating a DockerFile‚úçÔ∏è If you have gone through the installation process of installing Docker, you might have come across the hello-world example of docker. But in our case, let\u0026rsquo;s redo the hello-world example in Python, but by building our own Docker image.\nFirst thing is to create a simple Python script by placing the following line inside:\nprint(f\u0026#39;Hello world from inside the Docker container!\u0026#39;) Next step is to copy the below code into a file and naming it Dockerfile:\nFROM python WORKDIR /usr/src/app COPY hello_world.py ./ CMD [\u0026#34;python\u0026#34;, \u0026#34;hello_world.py\u0026#34;] In this file, we can see the following thing:\nThe first command we write is the FROM instruction, with the python image being used. Note that if we do not mention a default tag, then the latest tag is taken as default. The second instruction is setting the WORKDIR, which is like navigating to the /usr/src/app directory inside the container. The third instruction is COPY, which selects the hello_world.py to the current working directory set by the WORKDIR command The last instruction is CMD, which sets the default command to run when the image is started as a container. Building your image‚öíÔ∏è Once the above file is created, navigate to the folder containing the file and build the image using the Dockerfile that we created in the step above. The build command is used to build an image from a particular Dockerfile by using all the instructions from inside the Dockerfile. The -t flag is used to give a name and a tag to our image, similar to the name and the tag we see on Docker Hub. Run the following command in the terminal where the Dockerfile is located:\ndocker build -t custom_image:latest . Once the above command is run, we should see something like this in the terminal:\nStep 1/4 : FROM python latest: Pulling from library/python f2f58072e9ed: Pull complete 5c8cfbf51e6e: Pull complete aa3a609d1579: Pull complete 094e7d9bb04e: Pull complete 2cbfd734f382: Pull complete aa86ac293d0f: Pull complete 4cffc9f44941: Pull complete ae2c75627c86: Pull complete 2d2b74d2f0f7: Pull complete Digest: sha256:11560799e4311fd5abcca7ace13585756d7222ce5471162cd78c78a4ecaf62bd Status: Downloaded newer image for python:latest ---\u0026gt; 539eccd5ee4e Step 2/4 : WORKDIR /usr/src/app ---\u0026gt; Running in a63f44fb58c6 Removing intermediate container a63f44fb58c6 ---\u0026gt; 266dd62fca08 Step 3/4 : COPY hello_world.py ./ ---\u0026gt; 016f934d50e5 Step 4/4 : CMD [\u0026#34;python\u0026#34;, \u0026#34;hello_world.py\u0026#34;] ---\u0026gt; Running in b38de1b256fa Removing intermediate container b38de1b256fa ---\u0026gt; 432ba341135f Successfully built 432ba341135f Successfully tagged custom_image:latest As we analyze the output of the build command, we can see the following things:\nEvery instruction starts with the Step comment, followed by the step number which is currently being executed. For example, in Step 1/4, we can see that the docker engine is pulling the image from the Docker Hub to our local machine. Every instruction that we provided in the Dockerfile is echoed first, followed by its execution hash. Once all the instructions are executed, we get the final message saying Successfully built \u0026lt;hash\u0026gt; and Successfully tagged custom_image:latest. This message means that our custom image is now built. [Bonus]Running your custom imageüèÉ Once the above commands are run in the order we specify, we can check the list of images we have on our local machine by running the following command in the terminal:\ndocker images Here, we should see our custom_image being listed amongst other images, if any. Now that we have built our custom image, it is time to run it. For now, let\u0026rsquo;s copy the following command in the terminal to run the image as a container (Don\u0026rsquo;t worry about the below line of code, we will look at it in the here):\ndocker run custom_image:latest Once we execute the above command, we should see our print message in the terminal: Hello world from inside the Docker container!\nCongratulations!!ü•≥üéâ You have successfully built your first custom image. You are already a Docker Pro!!ü§ì\nSumming Up!üí° We saw in this post how once can either pull images from the Docker Hub or create their own custom images, and run them from the terminal. The next) post will now focus more on the later part of running the image once we have it on our machine.\nUntil then, Cheers!!üï∫üíÉ\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_images/","summary":"Docker Imagesüê≥ As we saw in the basics of Docker post, the base flow of every Docker container is an image. A Docker image, whether custom or pre-built, is absolutely necessary for us to be able to run anything using Docker.\nIn essence, a Docker image is a union of layered filesystem stacked on top of each other. This stands true fro pre-built images as well as custom images that we might create using some pre-built image as a base.","title":"Docker Images and DockerFile"},{"content":"Why and What? In Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill, as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.\nThis is the very scenario where things can fall apart very easily!\nWhy Docker? In scenarios like mentioned above, wouldn\u0026rsquo;t it be useful to have a tool that makes sure that a software is bundled in a way that is irrespective of the base dependencies it requires to be built on?\nAs I primarily work in Python, I would like to throw in an analogy. This abstraction tool can be thought of like a virual environment, with each project having its own separate dependencies which do not interfere with a different project\u0026rsquo;s virtual environment, and every project satisfies all the module level dependencies it has once run from inside the virtual environment.\nHaving such a tool to manage whole software, such that it handles all the base dependencies like that of the OS and any other package level dependencies are managed for us would be great, wouldn\u0026rsquo;t it?\nWhat is Docker? In-line with the objectives that we want the above-mentioned tool to perform, let\u0026rsquo;s take a look at Docker.\nDocker helps abstract away the dependencies for components between varying OS and hardware requirements, and lets every part of the project run in an isolated environment.\nFeels like technical mumbo jumbo? Well let\u0026rsquo;s take another go at understanding this. The abstraction that Docker provides can be thought of in the following way:\nImagine breaking the whole software into multiple smaller pieces, with each piece handling one complete part of some logic. This is what we call an isolated part of the project. For the whole application to be able to run, we need each of the isolated part of the project we created in the step above to be able to run. To be able to run each isolated part of the project, we need to satisfy the dependencies that every isolated part needs. Satisfying these dependencies can be thought of as creating environments for each part of the project that we isolated. I hope it is more or less clear what Docker does. If not, fret not! Things should become clearer as we go further with terminology.\nTerminology So far, we have been trying to understand what Docker does in our own analogy and terms. However, things can go out of hand if one does not follow a standard terminology.\nLet\u0026rsquo;s dive in the terminology that will make our life easier to follow.\nObviously, one should at the end refer to the official glossary mentioned by Docker. However, to quickly get us started, I have mentioned some base terminologies below.\nImage Since we need to create an isolated environment, we first need to decide what will the base of such an environment have. This base that each isolated environment needs is defined in a Docker image, which contains union of layered filesystems stacked on top of each other.\nWe can think of image as a small pre-compiled software on which we can run our assigned part of the project, and using an image is like installing Python or Ubuntu on your own machine.\nBecause of the awesome strength of the Docker community, they decided to keep a collection of the images that people need. This collection of images is listed on the Docker Hub, and we can find all sorts of images, like Alpine Linux and Python.\nNote: Although the Docker hub has many images readily available, we can also create our own Docker images.\nContainer With the image\nlike having multiple small-separate machines running different pieces of the software (which we specify), running the whole software as Lego blocks, with each of the small machines helping each other.\nContainers in Docker have their own network, their own volume mounts, their own networks, and are just like VMs. The only difference is that all the containers share the same os as the machine on which they are running, unlike VMs who also have their own OS when created.\nContainer use the kernel to run their process. In such, a linux based OS will only be able to run linux based containers on it, and a windows based container will not be able to run on a windows based machine.\nImages in Docker are packages or templates that are used to create one or more containers. every container needs an image to be able to run.\nDockerFile is the configuration of an image should be initialized. DockerFile creates a Docker image, and image runs a container.\n","permalink":"https://tanmaychimurkar.github.io/posts/docker/docker_containers/","summary":"Why and What? In Software Development cycle, developers of every level have either heard or said the following:\nIt works on my machine, I am not sure why it isn\u0026rsquo;t running on yours\nDifferent software projects have different dependencies, that only keep going uphill, as the product itself evolves. When this happens, we need to make sure all interactions between different components have been done correctly in order for the whole application to come together and run.","title":"The basics of Images to get started"}]